{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Annotations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Machine-Learning-Course/blob/main/Final_Project/Annotations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvHWw5FNjHCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2177e03b-f82e-4f6e-b382-a09354f9fa02"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzvA1piVH8Ok"
      },
      "source": [
        "# !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1612402036&Signature=kWYXViEkaLRPaPo2VsruP69MIwZdQx6fn0ZHaYHoWkkwghC0EtqgucKw68JbXEeCZkb5NJw%2B6EMfmr2D3ZWInUm%2FYpIQwLqSP5XTx02Z1LqQ2xGElc%2B%2BwPXyvKzxD%2FVOHicxcb%2BVIHwz0oJGChISiLns%2BJR3fS8kq1XRx%2Bp9uZ8%2Btqt600gQuVg05ssXZq1CCK%2BlyqfY11tKozZG%2FX59wpsgZc6Y5nGSb409Kofx3ZTiSN6ZeW0xndaR3nWQoECj7pxOjJ7RCZh2LEyGC29LAvw7oUWyqG4POYXOTbZnAMnXJ7XuMqVxeQ9ZE7AAA5tAIv9htqPm5LNKo2mgA86wHg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.zip'\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train_annotations.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1612402115&Signature=fljQmsTcuMbWv5yrNvEYRDy5wa4LUhuaTOXdWVzbducrIlrRUIGQYscPharuVqkybQVBr3QF6abCtKCA2RxVpkoL5dbP6r7wfBPXPbtW2VEcwXs29rthcIEG4Xm8MFWhoNun2hERkWZu2oj%2F4SXTgo9J%2BhyYKdXSLzsf%2F1mdhD8m2D67VJHdBZiMPIx1Uu0igf4F01SLOFUyHvW1tPy6LT1T0%2FK0%2Bf3WiumcvxTCiUL07zRkM7%2F1RaLvV6Ureg5fZeY5Owq3GzT%2BjXWBVih7E5xPyHLxDQdYMi4YyaDyeWCo4uX8NloCTgyKMPYehF6yi2ZnVvajOJ%2B9zG9mp%2B%2BdJA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain_annotations.csv.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE0z02ObIO_J"
      },
      "source": [
        "# !mkdir /content/trainset\r\n",
        "# !mkdir /content/trainset/data/\r\n",
        "# !mkdir /content/trainset/data/1/\r\n",
        "# !unzip '/content/train.zip' -d /content/trainset/data/1/\r\n",
        "# !unzip '/content/train_annotations.csv.zip' -d /content/trainset/annotations/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "4N1FWlaEJTw8",
        "outputId": "3b96332e-28fb-4f00-ebb4-22b1dd5d3c5f"
      },
      "source": [
        "import pandas as pd \r\n",
        "annotations = pd.read_csv('/content/trainset/annotations/train_annotations.csv')\r\n",
        "annotations.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StudyInstanceUID</th>\n",
              "      <th>label</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.12616281126973421762...</td>\n",
              "      <td>CVC - Normal</td>\n",
              "      <td>[[1487, 1279], [1477, 1168], [1472, 1052], [14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.12616281126973421762...</td>\n",
              "      <td>CVC - Normal</td>\n",
              "      <td>[[1328, 7], [1347, 101], [1383, 193], [1400, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.72921907356394389969...</td>\n",
              "      <td>CVC - Borderline</td>\n",
              "      <td>[[801, 1207], [812, 1112], [823, 1023], [842, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.11697104485452001927...</td>\n",
              "      <td>CVC - Normal</td>\n",
              "      <td>[[1366, 961], [1411, 861], [1453, 751], [1508,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.87704688663091069148...</td>\n",
              "      <td>NGT - Normal</td>\n",
              "      <td>[[1862, 14], [1845, 293], [1801, 869], [1716, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    StudyInstanceUID  ...                                               data\n",
              "0  1.2.826.0.1.3680043.8.498.12616281126973421762...  ...  [[1487, 1279], [1477, 1168], [1472, 1052], [14...\n",
              "1  1.2.826.0.1.3680043.8.498.12616281126973421762...  ...  [[1328, 7], [1347, 101], [1383, 193], [1400, 2...\n",
              "2  1.2.826.0.1.3680043.8.498.72921907356394389969...  ...  [[801, 1207], [812, 1112], [823, 1023], [842, ...\n",
              "3  1.2.826.0.1.3680043.8.498.11697104485452001927...  ...  [[1366, 961], [1411, 861], [1453, 751], [1508,...\n",
              "4  1.2.826.0.1.3680043.8.498.87704688663091069148...  ...  [[1862, 14], [1845, 293], [1801, 869], [1716, ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkPMdW9l_pHs",
        "outputId": "771d3e74-ad7b-437c-ed13-d475c2341174"
      },
      "source": [
        "len(annotations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhInlCf07y-3"
      },
      "source": [
        "import re\r\n",
        "import ast\r\n",
        "import numpy as np\r\n",
        "def str2array(s):\r\n",
        "    # Remove space after [\r\n",
        "    s=re.sub('\\[ +', '[', s.strip())\r\n",
        "    # Replace commas and spaces\r\n",
        "    s=re.sub('[,\\s]+', ', ', s)\r\n",
        "    return np.array(ast.literal_eval(s))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltu_ndY1Kgkk",
        "outputId": "e15ba626-7c34-4445-a345-0f48088b7bb7"
      },
      "source": [
        "import numpy as np \r\n",
        "\r\n",
        "##############\r\n",
        "msk_for_dataset_subset = np.random.rand(len(annotations)) < 0.15\r\n",
        "dataset_subset = annotations[msk_for_dataset_subset]\r\n",
        "##############\r\n",
        "\r\n",
        "msk = np.random.rand(len(dataset_subset)) > 0.25\r\n",
        "train_samples = dataset_subset[msk]\r\n",
        "validation_samples = dataset_subset[~msk]\r\n",
        "\r\n",
        "##############\r\n",
        "train_samples = train_samples[:5000]\r\n",
        "validation_samples = validation_samples[:1500]\r\n",
        "##############\r\n",
        "print('number of train samples: ', len(train_samples))\r\n",
        "print('number of validation samples: ', len(validation_samples))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "sample = dataset_subset.iloc[1, :]\r\n",
        "landmarks = sample['data']\r\n",
        "# print(landmarks)\r\n",
        "landmarks = np.array(str2array(landmarks))\r\n",
        "# print(type(landmarks))\r\n",
        "# landmarks = np.array(list(landmarks))\r\n",
        "print(\"sample landmark shape: \", landmarks.shape)\r\n",
        "# print(landmarks)\r\n",
        "\r\n",
        "# print('Image name: {}'.format(img_name))\r\n",
        "# print('Landmarks shape: {}'.format(landmarks.shape))\r\n",
        "# print('First 4 Landmarks: {}'.format(landmarks[:4]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train samples:  2026\n",
            "number of validation samples:  700\n",
            "sample landmark shape:  (13, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDO0eWSppIjD"
      },
      "source": [
        "from PIL import Image\r\n",
        "import random\r\n",
        "import torch.nn.functional as F\r\n",
        "from math import cos, sin, radians\r\n",
        "import imutils\r\n",
        "import cv2\r\n",
        "\r\n",
        "\r\n",
        "class RANZCRDataset():\r\n",
        "\r\n",
        "\r\n",
        "    def __init__(self, csv_file='/content/trainset/train.csv', root_dir='/content/trainset/data/1', transform=None, images_name=None):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            csv_file (string): Path to the csv file with annotations.\r\n",
        "            root_dir (string): Directory with all the images.\r\n",
        "            transform (callable, optional): Optional transform to be applied\r\n",
        "                on a sample.\r\n",
        "        \"\"\"\r\n",
        "        self.Images_name = images_name\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.transform = transform\r\n",
        "        \r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.Images_name)\r\n",
        "\r\n",
        "    #############\r\n",
        "\r\n",
        "\r\n",
        "    # def get_rot_mat(self, theta):\r\n",
        "\r\n",
        "    #   theta = torch.tensor(theta)\r\n",
        "    #   return torch.tensor([[torch.cos(theta), -torch.sin(theta), 0],\r\n",
        "    #                         [torch.sin(theta), torch.cos(theta), 0]])\r\n",
        "\r\n",
        "\r\n",
        "    # def rot_img_landmark(self, x, landmarks, theta, dtype):\r\n",
        "    #     rot_mat = self.get_rot_mat(theta)[None, ...].type(dtype).repeat(x.shape[0],1,1)\r\n",
        "    #     grid = F.affine_grid(rot_mat, x.size()).type(dtype)\r\n",
        "    #     image = F.grid_sample(x, grid)\r\n",
        "    #     landmarks = landmarks - 0.5\r\n",
        "    #     new_landmarks = np.matmul(landmarks, transformation_matrix)\r\n",
        "    #     new_landmarks = new_landmarks + 0.5\r\n",
        "    #     return image, new_landmarks\r\n",
        "\r\n",
        "\r\n",
        "    ##############\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        centerCrop_value = 904\r\n",
        "        if torch.is_tensor(idx):\r\n",
        "            idx = idx.tolist()\r\n",
        "\r\n",
        "        img_name = os.path.join(self.root_dir,\r\n",
        "                                self.Images_name.iloc[idx, 0])\r\n",
        "        image = Image.open(img_name + '.jpg').convert('RGB')\r\n",
        "        labels = self.Images_name.iloc[idx, -1]\r\n",
        "        labels = torch.from_numpy(str2array(labels))\r\n",
        "        sample = {'image': image, 'label': labels }\r\n",
        "\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "\r\n",
        "          \r\n",
        "          tmp = np.zeros((100, 2))\r\n",
        "\r\n",
        "          for i in range(0, (sample['label'].shape[0]) ):\r\n",
        "            tmp[i, 0] = ( (centerCrop_value / np.array(image).shape[1]) * np.array(sample['label'])[i, 0] ) / centerCrop_value\r\n",
        "            tmp[i, 1] = ( (centerCrop_value / np.array(image).shape[0]) * np.array(sample['label'])[i, 1] ) / centerCrop_value\r\n",
        "             \r\n",
        "\r\n",
        "          sample['label'] = torch.from_numpy(tmp).type(torch.float16)\r\n",
        "\r\n",
        "\r\n",
        "          sample['image'] = self.transform(sample['image'])\r\n",
        "\r\n",
        "\r\n",
        "          # # random rotation\r\n",
        "          # image, landmark = self.rot_img_landmark(sample['image'], sample['label'], np.pi/2, dtype= torch.FloatTensor)\r\n",
        "          # print(type(image), image.shape)\r\n",
        "          # print(type(landmark), landmark.shape)\r\n",
        "          \r\n",
        "\r\n",
        "        return sample\r\n",
        "\r\n",
        "# my_dataset = RANZCRDataset\r\n",
        "# my_dataset.__getitem__(self, 4)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BojvstcXDbmN"
      },
      "source": [
        "\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision import transforms, utils\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "import os\r\n",
        "\r\n",
        "# batch_size = 8\r\n",
        "mean = np.array([0.4823, 0.4823, 0.4823])\r\n",
        "std = np.array([0.191473164, 0.191473164, 0.191473164])\r\n",
        "\r\n",
        "\r\n",
        "def load_data(csv_file='/content/trainset/annotations/train_annotations.csv', root_dir='/content/trainset/data/1'):\r\n",
        "\r\n",
        "  centerCrop_value = 904\r\n",
        "  transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "                                  transforms.Resize((1024, 1024)),\r\n",
        "                                  transforms.CenterCrop(centerCrop_value),\r\n",
        "                                  transforms.Normalize(mean, std)])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  trainset = RANZCRDataset(csv_file='/content/trainset/annotations/train_annotations.csv',\r\n",
        "                                      root_dir='/content/trainset/data/1', transform=transform, images_name=train_samples)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  validation_set = RANZCRDataset(csv_file='/content/trainset/annotations/train_annotations.csv',\r\n",
        "                                    root_dir='/content/trainset/data/1', transform=transform, images_name=validation_samples)\r\n",
        "  \r\n",
        "\r\n",
        "  return trainset, validation_set\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L2-Z934TG4k"
      },
      "source": [
        "\r\n",
        "# train_loader = torch.utils.data.DataLoader(trainset,\r\n",
        "#                          batch_size=batch_size,\r\n",
        "#                          num_workers=0,\r\n",
        "#                          shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# validation_loader = torch.utils.data.DataLoader(trainset,\r\n",
        "#                          batch_size=batch_size,\r\n",
        "#                          num_workers=0,\r\n",
        "#                          shuffle=True)\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHNoNytaOALb"
      },
      "source": [
        "# import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "# def imshow(img, landmarks):\r\n",
        "#     npimg = img.numpy()\r\n",
        "#     npimg = ((npimg * std[0]) + mean[0]) # unnormalize\r\n",
        "#     plt.imshow((np.transpose(npimg, (1, 2, 0)) * 255).astype(np.uint8))\r\n",
        "#     for i in range(landmarks.shape[0]):\r\n",
        "#       landmarks[i, :, 0] = landmarks[i, :, 0] + (centerCrop_value*i)\r\n",
        "#     plt.scatter(landmarks[:, :, 0], landmarks[:, :, 1], s=10, marker='.', c='r')\r\n",
        "#     plt.pause(0.001)  # pause a bit so that plots are updated\r\n",
        "#     plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# # get some random training images\r\n",
        "# dataiter = iter(train_loader)\r\n",
        "# sample = dataiter.next()\r\n",
        "\r\n",
        "# imshow(torchvision.utils.make_grid(sample['image']), sample['label'])\r\n",
        "# print(sample['label'].shape)\r\n",
        "# print(sample['image'].shape)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05o0AD8DzDyf"
      },
      "source": [
        "# class Network(nn.Module):\r\n",
        "  \r\n",
        "#   def __init__(self):\r\n",
        "#     super(Network, self).__init__()\r\n",
        "#     self.model = model\r\n",
        "#     self.conv1 = nn.Conv2d(3, 3, 5)\r\n",
        "#     self.conv2 = nn.Conv2d(3, 3, 1)\r\n",
        "#     self.pool2 = nn.MaxPool2d(2, 2)\r\n",
        "#     self.sigmoid = nn.Sigmoid()\r\n",
        "#     self.fc_final = nn.Linear(1000, 11)\r\n",
        "\r\n",
        "#   def forward(self, x):\r\n",
        "\r\n",
        "#     x = self.pool2(F.relu(self.conv1(x)))\r\n",
        "#     x = self.pool2(F.relu(self.conv2(x)))\r\n",
        "#     x = self.model(x)\r\n",
        "#     x = self.sigmoid(self.fc_final(x))\r\n",
        "#     return x\r\n",
        "\r\n",
        "# Network = Network()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdKfqyGawGY8"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "from torchvision import models\r\n",
        "from torch import optim\r\n",
        "import time\r\n",
        "\r\n",
        "model = models.resnet18(pretrained=True)\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9nsdk53Ufm2"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F \r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self, l1=512, l2=256, c1=3):\r\n",
        "    super(Net, self).__init__()\r\n",
        "    self.model = model\r\n",
        "    self.conv1 = nn.Conv2d(3, c1, 5)\r\n",
        "    self.conv2 = nn.Conv2d(c1, 3, 1)\r\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\r\n",
        "    self.sigmoid = nn.Sigmoid()\r\n",
        "    self.fc1 = nn.Linear(1000, l1)\r\n",
        "    self.fc2 = nn.Linear(l1, l2)\r\n",
        "    self.fc_final = nn.Linear(l2, 200)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    x = self.pool2(F.relu(self.conv1(x)))\r\n",
        "    x = self.pool2(F.relu(self.conv2(x)))\r\n",
        "    x = self.model(x)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = F.relu(self.fc2(x))\r\n",
        "    x = self.sigmoid((self.fc_final(x)))\r\n",
        "    return x\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAhsF_T4UxTv"
      },
      "source": [
        "# ###################################\r\n",
        "# !pip install ray\r\n",
        "# !pip install tensorboardX"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5tHqN1MUqo_"
      },
      "source": [
        "from functools import partial\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import random_split\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from ray import tune\r\n",
        "from ray.tune import CLIReporter\r\n",
        "from ray.tune.schedulers import ASHAScheduler\r\n",
        "import tensorboardX"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugZO6cnRUvF2"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "def r2_score(y_targets, y_preds):\r\n",
        "\r\n",
        "    \r\n",
        "    try:\r\n",
        "        from sklearn.metrics import r2_score\r\n",
        "    except ImportError:\r\n",
        "        raise RuntimeError(\"This contrib module requires sklearn to be installed.\")\r\n",
        "\r\n",
        "\r\n",
        "    y_true = y_targets.cpu().detach().numpy().astype('float16')\r\n",
        "    y_pred = y_preds.cpu().detach().numpy().astype('float16')\r\n",
        "    try: \r\n",
        "      return r2_score(y_true, y_pred)\r\n",
        "    except ValueError:\r\n",
        "      return 0\r\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyc_At_1VJ2j"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "def train_ranzcr_landmark(config, checkpoint_dir=None, data_dir=None):\r\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\r\n",
        "\r\n",
        "    device = \"cpu\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = \"cuda:0\"\r\n",
        "        if torch.cuda.device_count() > 1:\r\n",
        "            net = nn.DataParallel(net)\r\n",
        "    net.to(device)\r\n",
        "\r\n",
        "    criterion = nn.MSELoss()\r\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], weight_decay=config[\"wd\"])\r\n",
        "\r\n",
        "    if checkpoint_dir:\r\n",
        "        model_state, optimizer_state = torch.load(\r\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\r\n",
        "        net.load_state_dict(model_state)\r\n",
        "        optimizer.load_state_dict(optimizer_state)\r\n",
        "\r\n",
        "    trainset, testset = load_data(data_dir)\r\n",
        "\r\n",
        "    test_abs = int(len(trainset) * 0.8)\r\n",
        "    train_subset, val_subset = random_split(\r\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\r\n",
        "    \r\n",
        "    trainloader = torch.utils.data.DataLoader(\r\n",
        "        train_subset,\r\n",
        "        batch_size=int(config[\"batch_size\"]),\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=8)\r\n",
        "    valloader = torch.utils.data.DataLoader(\r\n",
        "        val_subset,\r\n",
        "        batch_size=int(config[\"batch_size\"]),\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=8)\r\n",
        "\r\n",
        "    for epoch in range(10):  # loop over the dataset multiple times\r\n",
        "        running_loss = 0.0\r\n",
        "        epoch_steps = 0\r\n",
        "        for i, data in enumerate(trainloader, 0):\r\n",
        "            # get the inputs; data is a list of [inputs, labels]\r\n",
        "            inputs, labels_temp = data['image'].float(), data['label']\r\n",
        "            batch_size = int(inputs.shape[0])\r\n",
        "            labels = np.zeros((batch_size, 200))\r\n",
        "            for i in range(batch_size):\r\n",
        "              labels[i, :100] = labels_temp[i, :, 0]\r\n",
        "              labels[i, 100:] = labels_temp[i, :, 1]\r\n",
        "\r\n",
        "            labels = (torch.from_numpy(labels)).type(torch.float16)\r\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "            # zero the parameter gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # forward + backward + optimize\r\n",
        "            outputs = (net(inputs)).type(torch.float16)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            # print statistics\r\n",
        "            running_loss += loss.item()\r\n",
        "            epoch_steps += 1\r\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\r\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\r\n",
        "                                                running_loss / epoch_steps))\r\n",
        "                running_loss = 0.0\r\n",
        "\r\n",
        "        # Validation loss\r\n",
        "        val_loss = 0.0\r\n",
        "        val_steps = 0\r\n",
        "        total = 0\r\n",
        "        correct = 0\r\n",
        "        accuracy = 0\r\n",
        "        batch_counter = 0\r\n",
        "        for i, data in enumerate(valloader, 0):\r\n",
        "            with torch.no_grad():\r\n",
        "                inputs, labels_temp = data['image'].float(), data['label']\r\n",
        "                batch_size = int(inputs.shape[0])\r\n",
        "                labels = np.zeros((batch_size, 200))\r\n",
        "                for i in range(batch_size):\r\n",
        "                  labels[i, :100] = labels_temp[i, :, 0]\r\n",
        "                  labels[i, 100:] = labels_temp[i, :, 1]\r\n",
        "\r\n",
        "                labels = (torch.from_numpy(labels)).type(torch.float16)\r\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "                outputs = (net(inputs)).type(torch.float16)\r\n",
        "                # _, predicted = torch.max(outputs.data, 1)\r\n",
        "                # total += labels.size(0)\r\n",
        "                # correct += (predicted == labels).sum().item()\r\n",
        "                # my_validation_outputs = (outputs > 0.5)\r\n",
        "                # print('------------------------------------------------------------------------------')\r\n",
        "                # print(labels)\r\n",
        "                # print(my_validation_outputs)\r\n",
        "                # print('------------------------------------------------------------------------------')\r\n",
        "                # accuracy += auc_s(labels, my_validation_outputs)\r\n",
        "                # batch_counter += 1\r\n",
        "                accuracy += r2_score(labels, outputs)\r\n",
        "                batch_counter += 1\r\n",
        "\r\n",
        "                loss = criterion(outputs, labels)\r\n",
        "                val_loss += loss.cpu().numpy()\r\n",
        "                val_steps += 1\r\n",
        "\r\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\r\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\r\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\r\n",
        "\r\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=(accuracy / batch_counter))\r\n",
        "    torch.save((net.state_dict(), optimizer.state_dict()), '/content/drive/MyDrive/RANZCR/model_landmark_%.3f.pth'%(accuracy / batch_counter))\r\n",
        "    print(\"Finished Training\")\r\n",
        "\r\n",
        "\r\n",
        "            "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRwirW14ZY3g"
      },
      "source": [
        "\r\n",
        "def test_accuracy(net, device=\"cpu\"):\r\n",
        "    trainset, testset = load_data()\r\n",
        "\r\n",
        "    testloader = torch.utils.data.DataLoader(\r\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2)\r\n",
        "\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    batch_counter_test = 0\r\n",
        "    accuracy_test = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in testloader:\r\n",
        "            images, labels = data['image'].float(), data['label']\r\n",
        "            batch_size = int(inputs.shape[0])\r\n",
        "            labels = np.zeros((batch_size, 200))\r\n",
        "            for i in range(batch_size):\r\n",
        "              labels[i, :100] = labels_temp[i, :, 0]\r\n",
        "              labels[i, 100:] = labels_temp[i, :, 1]\r\n",
        "\r\n",
        "            labels = (torch.from_numpy(labels)).type(torch.float16)\r\n",
        "            images, labels = images.to(device), labels.to(device)\r\n",
        "            outputs = (net(images)).type(torch.float16)\r\n",
        "            # _, predicted = torch.max(outputs.data, 1)\r\n",
        "            # total += labels.size(0)\r\n",
        "            # correct += (predicted == labels).sum().item()\r\n",
        "            # my_test_outputs = (outputs > 0.5)\r\n",
        "            # accuracy_test += accuracy_score(labels, my_test_outputs)\r\n",
        "            # batch_counter_test += 1\r\n",
        "            accuracy_test += r2_score(labels, outputs)\r\n",
        "            batch_counter_test += 1\r\n",
        "\r\n",
        "\r\n",
        "    return accuracy_test / batch_counter_test"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aCE8hHqZzri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fa6928-23ea-4c13-db7c-2a3575392a10"
      },
      "source": [
        "\r\n",
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\r\n",
        "    data_dir = os.path.abspath(\"/content/trainset/data\")\r\n",
        "    load_data(data_dir)\r\n",
        "    config = {\r\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(8, 9)),\r\n",
        "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(8, 9)),\r\n",
        "        \"lr\": tune.loguniform(1e-5, 1e-1),\r\n",
        "        \"wd\": tune.loguniform(1e-6, 1e-2),\r\n",
        "        \"c1\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 6)),\r\n",
        "        \"batch_size\": tune.choice([4, 8, 16])\r\n",
        "    }\r\n",
        "    scheduler = ASHAScheduler(\r\n",
        "        metric=\"loss\",\r\n",
        "        mode=\"min\",\r\n",
        "        max_t=max_num_epochs,\r\n",
        "        grace_period=1,\r\n",
        "        reduction_factor=2)\r\n",
        "    reporter = CLIReporter(\r\n",
        "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\r\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\r\n",
        "\r\n",
        "    result = tune.run(\r\n",
        "            partial(train_ranzcr_landmark, data_dir=data_dir),\r\n",
        "            resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\r\n",
        "            config=config,\r\n",
        "            num_samples=num_samples,\r\n",
        "            scheduler=scheduler,\r\n",
        "            progress_reporter=reporter)\r\n",
        "      \r\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\r\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\r\n",
        "    print(\"Best trial final validation loss: {}\".format(\r\n",
        "        best_trial.last_result[\"loss\"]))\r\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\r\n",
        "        best_trial.last_result[\"accuracy\"]))\r\n",
        "\r\n",
        "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\r\n",
        "    device = \"cpu\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = \"cuda:0\"\r\n",
        "        if gpus_per_trial > 1:\r\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\r\n",
        "    best_trained_model.to(device)\r\n",
        "\r\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\r\n",
        "    model_state, optimizer_state = torch.load(os.path.join(best_checkpoint_dir, \"checkpoint\"))\r\n",
        "    best_trained_model.load_state_dict(model_state)\r\n",
        "    test_acc = test_accuracy(best_trained_model, device)\r\n",
        "    torch.save(best_trained_model.state_dict(), '/content/drive/MyDrive/RANZCR/model_landmark_%.3f.pth'%(test_acc) )\r\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # You can change the number of GPUs per trial here:\r\n",
        "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-01 22:08:12,634\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "2021-02-01 22:08:15,714\tWARNING experiment.py:285 -- No name detected on trainable. Using DEFAULT.\n",
            "2021-02-01 22:08:15,716\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n",
            "2021-02-01 22:08:17,561\tWARNING worker.py:1034 -- Warning: The actor ImplicitFunc has size 47591543 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 1.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 1/10 (1 RUNNING)\n",
            "+---------------------+----------+-------+--------------+------+------+------+-----------+-----------+\n",
            "| Trial name          | status   | loc   |   batch_size |   c1 |   l1 |   l2 |        lr |        wd |\n",
            "|---------------------+----------+-------+--------------+------+------+------+-----------+-----------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  |       |            8 |   32 |  256 |  256 | 0.0345667 | 0.0011671 |\n",
            "+---------------------+----------+-------+--------------+------+------+------+-----------+-----------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -564.6728610961762\n",
            "  date: 2021-02-01_22-24-57\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.07967601102941177\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 998.5769119262695\n",
            "  time_this_iter_s: 998.5769119262695\n",
            "  time_total_s: 998.5769119262695\n",
            "  timestamp: 1612218297\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 3.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |     loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.079676 |   -564.673 |                    1 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |          |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -333.0375624669193\n",
            "  date: 2021-02-01_22-41-26\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.01969131768918505\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1987.4952473640442\n",
            "  time_this_iter_s: 988.9183354377747\n",
            "  time_total_s: 1987.4952473640442\n",
            "  timestamp: 1612219286\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.7/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0196913 |   -333.038 |                    2 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -17.136987302774767\n",
            "  date: 2021-02-01_22-57-40\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 3\n",
            "  loss: 0.018049053117340685\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2961.9544134140015\n",
            "  time_this_iter_s: 974.4591660499573\n",
            "  time_total_s: 2961.9544134140015\n",
            "  timestamp: 1612220260\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.8/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0180491 |    -17.137 |                    3 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -41.403640501178415\n",
            "  date: 2021-02-01_23-14-07\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.017670575310202205\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 3948.5919036865234\n",
            "  time_this_iter_s: 986.637490272522\n",
            "  time_total_s: 3948.5919036865234\n",
            "  timestamp: 1612221247\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.8/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0176706 |   -41.4036 |                    4 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -22.510742320270342\n",
            "  date: 2021-02-01_23-30-40\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 5\n",
            "  loss: 0.017533246208639705\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 4942.021183490753\n",
            "  time_this_iter_s: 993.4292798042297\n",
            "  time_total_s: 4942.021183490753\n",
            "  timestamp: 1612222240\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0175332 |   -22.5107 |                    5 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -24.034305324788573\n",
            "  date: 2021-02-01_23-47-11\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 6\n",
            "  loss: 0.017406837612974877\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 5932.145201921463\n",
            "  time_this_iter_s: 990.1240184307098\n",
            "  time_total_s: 5932.145201921463\n",
            "  timestamp: 1612223231\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 6\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0174068 |   -24.0343 |                    6 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -32.86557640977091\n",
            "  date: 2021-02-02_00-03-43\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 7\n",
            "  loss: 0.017354628619025734\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 6924.707651138306\n",
            "  time_this_iter_s: 992.5624492168427\n",
            "  time_total_s: 6924.707651138306\n",
            "  timestamp: 1612224223\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 7\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0173546 |   -32.8656 |                    7 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -39.11947821146389\n",
            "  date: 2021-02-02_00-20-09\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 8\n",
            "  loss: 0.0173341339709712\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 7910.785983800888\n",
            "  time_this_iter_s: 986.0783326625824\n",
            "  time_total_s: 7910.785983800888\n",
            "  timestamp: 1612225209\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 8\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 5.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0173341 |   -39.1195 |                    8 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -49.917890527758715\n",
            "  date: 2021-02-02_00-36-37\n",
            "  done: false\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 9\n",
            "  loss: 0.017233455882352942\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 8898.86537361145\n",
            "  time_this_iter_s: 988.0793898105621\n",
            "  time_total_s: 8898.86537361145\n",
            "  timestamp: 1612226197\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 9\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 5.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0172335 |   -49.9179 |                    9 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00000:\n",
            "  accuracy: -38.37137185296275\n",
            "  date: 2021-02-02_00-53-15\n",
            "  done: true\n",
            "  experiment_id: b776cde987bc4d168d408ffe273a34ad\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 10\n",
            "  loss: 0.017175861433440565\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4841\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 9896.942204475403\n",
            "  time_this_iter_s: 998.0768308639526\n",
            "  time_total_s: 9896.942204475403\n",
            "  timestamp: 1612227195\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 10\n",
            "  trial_id: fbef5_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=1\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.07967601102941177\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 2/10 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |         wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00000 | RUNNING  | 172.28.0.2:4841 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671  | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | PENDING  |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074 |           |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+-------------+------------+-----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-02 00:53:17,052\tWARNING util.py:142 -- The `start_trial` operation took 0.892 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_fbef5_00001:\n",
            "  accuracy: -673.5599244101195\n",
            "  date: 2021-02-02_01-09-43\n",
            "  done: true\n",
            "  experiment_id: 6ebecd2982c74c67ada66e25c22db110\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.22029861749387256\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 4842\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 984.9648914337158\n",
            "  time_this_iter_s: 984.9648914337158\n",
            "  time_total_s: 984.9648914337158\n",
            "  timestamp: 1612228183\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fbef5_00001\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=2\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.14998731426164216\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 3/10 (1 PENDING, 1 RUNNING, 1 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00001 | RUNNING    | 172.28.0.2:4842 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-02 01:09:44,860\tWARNING util.py:142 -- The `start_trial` operation took 0.873 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_fbef5_00002:\n",
            "  accuracy: -3409.8877941379465\n",
            "  date: 2021-02-02_01-26-18\n",
            "  done: true\n",
            "  experiment_id: 50a0b03504a54c92860c35945474cd2d\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.22270320012019232\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6078\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 991.5601739883423\n",
            "  time_this_iter_s: 991.5601739883423\n",
            "  time_total_s: 991.5601739883423\n",
            "  timestamp: 1612229178\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fbef5_00002\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.3/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 4/10 (1 PENDING, 1 RUNNING, 2 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00002 | RUNNING    | 172.28.0.2:6078 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | PENDING    |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-02 01:26:19,522\tWARNING util.py:142 -- The `start_trial` operation took 0.939 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_fbef5_00003:\n",
            "  accuracy: -456.1406769658429\n",
            "  date: 2021-02-02_01-42-26\n",
            "  done: false\n",
            "  experiment_id: 82c9014cf83645b4b630c3381949f06c\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.21941779641544118\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6167\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 964.972918510437\n",
            "  time_this_iter_s: 964.972918510437\n",
            "  time_total_s: 964.972918510437\n",
            "  timestamp: 1612230146\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fbef5_00003\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=3\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.21985820695465685\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 5/10 (1 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00003 | RUNNING    | 172.28.0.2:6167 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219418  |  -456.141  |                    1 |\n",
            "| DEFAULT_fbef5_00004 | PENDING    |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00003:\n",
            "  accuracy: -773.7427538847609\n",
            "  date: 2021-02-02_01-58-44\n",
            "  done: true\n",
            "  experiment_id: 82c9014cf83645b4b630c3381949f06c\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.21942737055759803\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6167\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1942.8240878582\n",
            "  time_this_iter_s: 977.8511693477631\n",
            "  time_total_s: 1942.8240878582\n",
            "  timestamp: 1612231124\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: fbef5_00003\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=4\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.11955934412339154 | Iter 1.000: -0.21985820695465685\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 5/10 (1 PENDING, 1 RUNNING, 3 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00003 | RUNNING    | 172.28.0.2:6167 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | PENDING    |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-02 01:58:45,287\tWARNING util.py:142 -- The `start_trial` operation took 0.813 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_fbef5_00004:\n",
            "  accuracy: -2201.6723315697864\n",
            "  date: 2021-02-02_02-15-05\n",
            "  done: true\n",
            "  experiment_id: b4ee617fb0464646a58b10aeebafa707\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.22350595511642157\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6325\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 978.0542726516724\n",
            "  time_this_iter_s: 978.0542726516724\n",
            "  time_total_s: 978.0542726516724\n",
            "  timestamp: 1612232105\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fbef5_00004\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.3/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=5\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.11955934412339154 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 6/10 (1 PENDING, 1 RUNNING, 4 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00004 | RUNNING    | 172.28.0.2:6325 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | PENDING    |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-02 02:15:06,379\tWARNING util.py:142 -- The `start_trial` operation took 0.886 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_fbef5_00005:\n",
            "  accuracy: -2226.808133538722\n",
            "  date: 2021-02-02_02-31-29\n",
            "  done: true\n",
            "  experiment_id: 23c98cb40e8f423aa6b38310528f84c2\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.2232953239889706\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6415\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 980.8858935832977\n",
            "  time_this_iter_s: 980.8858935832977\n",
            "  time_total_s: 980.8858935832977\n",
            "  timestamp: 1612233089\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fbef5_00005\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.3/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.11955934412339154 | Iter 1.000: -0.22150090880703244\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 7/10 (1 PENDING, 1 RUNNING, 5 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00005 | RUNNING    | 172.28.0.2:6415 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "| DEFAULT_fbef5_00006 | PENDING    |                 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-02 02:31:30,199\tWARNING util.py:142 -- The `start_trial` operation took 0.860 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -133.13285587969062\n",
            "  date: 2021-02-02_02-47-54\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.01741476619944853\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 982.4685080051422\n",
            "  time_this_iter_s: 982.4685080051422\n",
            "  time_total_s: 982.4685080051422\n",
            "  timestamp: 1612234074\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.11955934412339154 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0174148 |  -133.133  |                    1 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -97.49523783540064\n",
            "  date: 2021-02-02_03-04-22\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.01701029609231388\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1970.2955441474915\n",
            "  time_this_iter_s: 987.8270361423492\n",
            "  time_total_s: 1970.2955441474915\n",
            "  timestamp: 1612235062\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0170103 |   -97.4952 |                    2 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -287.3677113821968\n",
            "  date: 2021-02-02_03-20-57\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 3\n",
            "  loss: 0.017083411123238357\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2964.9586510658264\n",
            "  time_this_iter_s: 994.663106918335\n",
            "  time_total_s: 2964.9586510658264\n",
            "  timestamp: 1612236057\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017670575310202205 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0170834 |  -287.368  |                    3 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -66.53963988250239\n",
            "  date: 2021-02-02_03-37-28\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.016757852890912223\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 3956.8892550468445\n",
            "  time_this_iter_s: 991.9306039810181\n",
            "  time_total_s: 3956.8892550468445\n",
            "  timestamp: 1612237048\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017214214100557214 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0167579 |   -66.5396 |                    4 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -80.50400873670425\n",
            "  date: 2021-02-02_03-53-54\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 5\n",
            "  loss: 0.01707780127431832\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 4942.14838886261\n",
            "  time_this_iter_s: 985.2591338157654\n",
            "  time_total_s: 4942.14838886261\n",
            "  timestamp: 1612238034\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017214214100557214 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0170778 |   -80.504  |                    5 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -122.43167717872906\n",
            "  date: 2021-02-02_04-10-26\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 6\n",
            "  loss: 0.016866085576076134\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 5934.193521022797\n",
            "  time_this_iter_s: 992.0451321601868\n",
            "  time_total_s: 5934.193521022797\n",
            "  timestamp: 1612239026\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 6\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017214214100557214 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0168661 |  -122.432  |                    6 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -80.36983156167088\n",
            "  date: 2021-02-02_04-27-01\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 7\n",
            "  loss: 0.016919416539809284\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 6929.5223343372345\n",
            "  time_this_iter_s: 995.3288133144379\n",
            "  time_total_s: 6929.5223343372345\n",
            "  timestamp: 1612240021\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 7\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.0173341339709712 | Iter 4.000: -0.017214214100557214 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0169194 |   -80.3698 |                    7 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -77.4439864955257\n",
            "  date: 2021-02-02_04-43-32\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 8\n",
            "  loss: 0.017091938093596815\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 7920.264523267746\n",
            "  time_this_iter_s: 990.7421889305115\n",
            "  time_total_s: 7920.264523267746\n",
            "  timestamp: 1612241012\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 8\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.01721303603228401 | Iter 4.000: -0.017214214100557214 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0170919 |   -77.444  |                    8 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -219.25224633238508\n",
            "  date: 2021-02-02_05-00-06\n",
            "  done: false\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 9\n",
            "  loss: 0.016977871165556067\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 8914.94258093834\n",
            "  time_this_iter_s: 994.6780576705933\n",
            "  time_total_s: 8914.94258093834\n",
            "  timestamp: 1612242006\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 9\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=6\n",
            "Bracket: Iter 8.000: -0.01721303603228401 | Iter 4.000: -0.017214214100557214 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0169779 |  -219.252  |                    9 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_fbef5_00006:\n",
            "  accuracy: -40.55108933813832\n",
            "  date: 2021-02-02_05-16-51\n",
            "  done: true\n",
            "  experiment_id: c0a7dac9cc754271b51c835341ad20dc\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 10\n",
            "  loss: 0.017048106474034926\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 6505\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 9919.742322921753\n",
            "  time_this_iter_s: 1004.7997419834137\n",
            "  time_total_s: 9919.742322921753\n",
            "  timestamp: 1612243011\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 10\n",
            "  trial_id: fbef5_00006\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 4.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=7\n",
            "Bracket: Iter 8.000: -0.01721303603228401 | Iter 4.000: -0.017214214100557214 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22029861749387256\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 8/10 (1 PENDING, 1 RUNNING, 6 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00006 | RUNNING    | 172.28.0.2:6505 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0170481 |   -40.5511 |                   10 |\n",
            "| DEFAULT_fbef5_00007 | PENDING    |                 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-02 05:16:52,974\tWARNING util.py:142 -- The `start_trial` operation took 0.849 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_fbef5_00007:\n",
            "  accuracy: -640.2408432406991\n",
            "  date: 2021-02-02_05-33-43\n",
            "  done: true\n",
            "  experiment_id: a0be6d2ad7fa417885d52e778c98eb9b\n",
            "  hostname: c3ea226c7cd8\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.22330416165865385\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 7207\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1008.8992195129395\n",
            "  time_this_iter_s: 1008.8992195129395\n",
            "  time_total_s: 1008.8992195129395\n",
            "  timestamp: 1612244023\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: fbef5_00007\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 5.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=8\n",
            "Bracket: Iter 8.000: -0.01721303603228401 | Iter 4.000: -0.017214214100557214 | Iter 2.000: -0.01969131768918505 | Iter 1.000: -0.22150090880703244\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-02-01_22-08-15\n",
            "Number of trials: 9/10 (1 PENDING, 1 RUNNING, 7 TERMINATED)\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "| Trial name          | status     | loc             |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |      loss |   accuracy |   training_iteration |\n",
            "|---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------|\n",
            "| DEFAULT_fbef5_00007 | RUNNING    | 172.28.0.2:7207 |           16 |   32 |  256 |  256 | 0.000170166 | 0.000259844 | 0.223304  |  -640.241  |                    1 |\n",
            "| DEFAULT_fbef5_00008 | PENDING    |                 |            8 |   32 |  256 |  256 | 0.0725285   | 0.000296957 |           |            |                      |\n",
            "| DEFAULT_fbef5_00000 | TERMINATED |                 |            8 |   32 |  256 |  256 | 0.0345667   | 0.0011671   | 0.0171759 |   -38.3714 |                   10 |\n",
            "| DEFAULT_fbef5_00001 | TERMINATED |                 |            4 |   16 |  256 |  256 | 0.000173957 | 0.00097074  | 0.220299  |  -673.56   |                    1 |\n",
            "| DEFAULT_fbef5_00002 | TERMINATED |                 |           16 |   32 |  256 |  256 | 0.00148455  | 0.000113452 | 0.222703  | -3409.89   |                    1 |\n",
            "| DEFAULT_fbef5_00003 | TERMINATED |                 |            8 |    8 |  256 |  256 | 0.000119612 | 1.42078e-05 | 0.219427  |  -773.743  |                    2 |\n",
            "| DEFAULT_fbef5_00004 | TERMINATED |                 |            8 |   16 |  256 |  256 | 5.97841e-05 | 9.89226e-05 | 0.223506  | -2201.67   |                    1 |\n",
            "| DEFAULT_fbef5_00005 | TERMINATED |                 |            8 |   16 |  256 |  256 | 0.000103335 | 0.00514357  | 0.223295  | -2226.81   |                    1 |\n",
            "| DEFAULT_fbef5_00006 | TERMINATED |                 |            4 |    8 |  256 |  256 | 0.0776037   | 0.000748052 | 0.0170481 |   -40.5511 |                   10 |\n",
            "+---------------------+------------+-----------------+--------------+------+------+------+-------------+-------------+-----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-02 05:33:44,872\tWARNING util.py:142 -- The `start_trial` operation took 0.881 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVUdllE-2WHE"
      },
      "source": [
        "\r\n",
        "#########################################################\r\n",
        "Network = Network()\r\n",
        "criterion = nn.MSELoss()\r\n",
        "optimizer = optim.Adam(Network.parameters(), lr=0.0075, weight_decay=1e-06)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BscbT2lMMMHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d71e1e-f072-4103-fcf7-9ed19421eede"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "print(count_parameters(model))\r\n",
        "print(count_parameters(Network))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60192808\n",
            "60328944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yOUc5MLn2H8B",
        "outputId": "4381a489-babb-435e-ae94-f9c4a26cc9b5"
      },
      "source": [
        "\r\n",
        "for epoch in range(40):\r\n",
        "\r\n",
        "  running_loss = 0.0\r\n",
        "  best_validation_loss = 1000000000000\r\n",
        "\r\n",
        "  for batch_number, data in enumerate(train_loader, 0):\r\n",
        "    \r\n",
        "  \r\n",
        "    inputs = data['image'].float()\r\n",
        "    label_temp = data['label']\r\n",
        "    label = np.zeros((batch_size, 136))\r\n",
        "    for i in range(batch_size):\r\n",
        "      if label_temp.shape[0] == batch_size:\r\n",
        "        label[i, :68] = label_temp[i, :, 0]\r\n",
        "        label[i, 68:] = label_temp[i, :, 1]\r\n",
        "      else:\r\n",
        "        pass\r\n",
        "\r\n",
        "    label = torch.from_numpy(label).float()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    outputs = Network(inputs)\r\n",
        "    loss = criterion(outputs, label)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    running_loss += loss.item()\r\n",
        "    if (batch_number % 10 == 0) and (batch_number > 9):\r\n",
        "      print('[epoch: %d, batch: %5d] training loss: %.3f' %( epoch + 1, batch_number, (running_loss/10)))\r\n",
        "      \r\n",
        "      dataiter = iter(validation_loader)\r\n",
        "      sample = dataiter.next()\r\n",
        "      validation_inputs = sample['image'].float()\r\n",
        "      validation_label_temp = data['label']\r\n",
        "      validation_label = np.zeros((batch_size, 136))\r\n",
        "      for i in range(batch_size):\r\n",
        "        if validation_label_temp.shape[0] == batch_size:\r\n",
        "          validation_label[i, :68] = validation_label_temp[i, :, 0]\r\n",
        "          validation_label[i, 68:] = validation_label_temp[i, :, 1]\r\n",
        "        else:\r\n",
        "          pass\r\n",
        "\r\n",
        "      validation_label = torch.from_numpy(validation_label).float()\r\n",
        "      validation_outputs = Network(validation_inputs)\r\n",
        "      validation_loss = criterion(validation_outputs, validation_label)\r\n",
        "      \r\n",
        "\r\n",
        "      print('[epoch: %d, batch: %5d] <validation 10 random sample> loss: %.3f' %( epoch + 1, batch_number, validation_loss))\r\n",
        "\r\n",
        "\r\n",
        "      running_loss = 0.0\r\n",
        "\r\n",
        "  try:\r\n",
        "    if validation_loss < best_validation_loss:\r\n",
        "      torch.save(Network.state_dict(), '/content/drive/MyDrive/landmarks.pth')\r\n",
        "      best_validation_loss = validation_loss\r\n",
        "  except ValueError:\r\n",
        "    pass\r\n",
        "  \r\n",
        "    \r\n",
        "print('Finished Training Network')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch: 1, batch:    10] training loss: 1570.635\n",
            "[epoch: 1, batch:    10] <validation 10 random sample> loss: 843.638\n",
            "[epoch: 1, batch:    20] training loss: 1057.810\n",
            "[epoch: 1, batch:    20] <validation 10 random sample> loss: 1391.703\n",
            "[epoch: 1, batch:    30] training loss: 960.650\n",
            "[epoch: 1, batch:    30] <validation 10 random sample> loss: 652.755\n",
            "[epoch: 1, batch:    40] training loss: 1222.799\n",
            "[epoch: 1, batch:    40] <validation 10 random sample> loss: 949.858\n",
            "[epoch: 1, batch:    50] training loss: 938.923\n",
            "[epoch: 1, batch:    50] <validation 10 random sample> loss: 509.950\n",
            "[epoch: 1, batch:    60] training loss: 1030.899\n",
            "[epoch: 1, batch:    60] <validation 10 random sample> loss: 762.595\n",
            "[epoch: 1, batch:    70] training loss: 1215.795\n",
            "[epoch: 1, batch:    70] <validation 10 random sample> loss: 1417.153\n",
            "[epoch: 1, batch:    80] training loss: 893.683\n",
            "[epoch: 1, batch:    80] <validation 10 random sample> loss: 1039.480\n",
            "[epoch: 1, batch:    90] training loss: 1018.521\n",
            "[epoch: 1, batch:    90] <validation 10 random sample> loss: 649.577\n",
            "[epoch: 1, batch:   100] training loss: 1074.565\n",
            "[epoch: 1, batch:   100] <validation 10 random sample> loss: 891.194\n",
            "[epoch: 1, batch:   110] training loss: 1119.393\n",
            "[epoch: 1, batch:   110] <validation 10 random sample> loss: 1316.683\n",
            "[epoch: 1, batch:   120] training loss: 950.886\n",
            "[epoch: 1, batch:   120] <validation 10 random sample> loss: 606.376\n",
            "[epoch: 1, batch:   130] training loss: 927.284\n",
            "[epoch: 1, batch:   130] <validation 10 random sample> loss: 843.970\n",
            "[epoch: 1, batch:   140] training loss: 993.847\n",
            "[epoch: 1, batch:   140] <validation 10 random sample> loss: 614.966\n",
            "[epoch: 1, batch:   150] training loss: 985.102\n",
            "[epoch: 1, batch:   150] <validation 10 random sample> loss: 1088.235\n",
            "[epoch: 1, batch:   160] training loss: 760.670\n",
            "[epoch: 1, batch:   160] <validation 10 random sample> loss: 1573.438\n",
            "[epoch: 1, batch:   170] training loss: 992.551\n",
            "[epoch: 1, batch:   170] <validation 10 random sample> loss: 835.367\n",
            "[epoch: 1, batch:   180] training loss: 868.540\n",
            "[epoch: 1, batch:   180] <validation 10 random sample> loss: 857.880\n",
            "[epoch: 1, batch:   190] training loss: 1217.459\n",
            "[epoch: 1, batch:   190] <validation 10 random sample> loss: 983.821\n",
            "[epoch: 1, batch:   200] training loss: 776.305\n",
            "[epoch: 1, batch:   200] <validation 10 random sample> loss: 815.152\n",
            "[epoch: 1, batch:   210] training loss: 826.282\n",
            "[epoch: 1, batch:   210] <validation 10 random sample> loss: 1381.476\n",
            "[epoch: 1, batch:   220] training loss: 1066.733\n",
            "[epoch: 1, batch:   220] <validation 10 random sample> loss: 932.474\n",
            "[epoch: 1, batch:   230] training loss: 1093.573\n",
            "[epoch: 1, batch:   230] <validation 10 random sample> loss: 1333.949\n",
            "[epoch: 1, batch:   240] training loss: 1258.374\n",
            "[epoch: 1, batch:   240] <validation 10 random sample> loss: 1097.282\n",
            "[epoch: 1, batch:   250] training loss: 1196.604\n",
            "[epoch: 1, batch:   250] <validation 10 random sample> loss: 1564.378\n",
            "[epoch: 1, batch:   260] training loss: 1144.250\n",
            "[epoch: 1, batch:   260] <validation 10 random sample> loss: 550.169\n",
            "[epoch: 1, batch:   270] training loss: 1079.524\n",
            "[epoch: 1, batch:   270] <validation 10 random sample> loss: 941.126\n",
            "[epoch: 1, batch:   280] training loss: 1220.965\n",
            "[epoch: 1, batch:   280] <validation 10 random sample> loss: 1083.836\n",
            "[epoch: 1, batch:   290] training loss: 1068.488\n",
            "[epoch: 1, batch:   290] <validation 10 random sample> loss: 901.171\n",
            "[epoch: 1, batch:   300] training loss: 1102.636\n",
            "[epoch: 1, batch:   300] <validation 10 random sample> loss: 488.279\n",
            "[epoch: 1, batch:   310] training loss: 920.370\n",
            "[epoch: 1, batch:   310] <validation 10 random sample> loss: 739.994\n",
            "[epoch: 1, batch:   320] training loss: 893.570\n",
            "[epoch: 1, batch:   320] <validation 10 random sample> loss: 887.417\n",
            "[epoch: 1, batch:   330] training loss: 1100.153\n",
            "[epoch: 1, batch:   330] <validation 10 random sample> loss: 941.371\n",
            "[epoch: 1, batch:   340] training loss: 990.339\n",
            "[epoch: 1, batch:   340] <validation 10 random sample> loss: 585.276\n",
            "[epoch: 1, batch:   350] training loss: 1187.670\n",
            "[epoch: 1, batch:   350] <validation 10 random sample> loss: 688.545\n",
            "[epoch: 1, batch:   360] training loss: 944.107\n",
            "[epoch: 1, batch:   360] <validation 10 random sample> loss: 1339.556\n",
            "[epoch: 1, batch:   370] training loss: 1090.649\n",
            "[epoch: 1, batch:   370] <validation 10 random sample> loss: 1655.709\n",
            "[epoch: 1, batch:   380] training loss: 954.594\n",
            "[epoch: 1, batch:   380] <validation 10 random sample> loss: 1745.225\n",
            "[epoch: 1, batch:   390] training loss: 950.777\n",
            "[epoch: 1, batch:   390] <validation 10 random sample> loss: 987.713\n",
            "[epoch: 1, batch:   400] training loss: 984.316\n",
            "[epoch: 1, batch:   400] <validation 10 random sample> loss: 1007.875\n",
            "[epoch: 1, batch:   410] training loss: 1079.439\n",
            "[epoch: 1, batch:   410] <validation 10 random sample> loss: 876.856\n",
            "[epoch: 1, batch:   420] training loss: 1278.245\n",
            "[epoch: 1, batch:   420] <validation 10 random sample> loss: 882.205\n",
            "[epoch: 1, batch:   430] training loss: 1197.446\n",
            "[epoch: 1, batch:   430] <validation 10 random sample> loss: 1785.441\n",
            "[epoch: 1, batch:   440] training loss: 786.887\n",
            "[epoch: 1, batch:   440] <validation 10 random sample> loss: 784.214\n",
            "[epoch: 1, batch:   450] training loss: 950.064\n",
            "[epoch: 1, batch:   450] <validation 10 random sample> loss: 1199.849\n",
            "[epoch: 1, batch:   460] training loss: 938.605\n",
            "[epoch: 1, batch:   460] <validation 10 random sample> loss: 621.195\n",
            "[epoch: 1, batch:   470] training loss: 1154.447\n",
            "[epoch: 1, batch:   470] <validation 10 random sample> loss: 2238.375\n",
            "[epoch: 1, batch:   480] training loss: 939.721\n",
            "[epoch: 1, batch:   480] <validation 10 random sample> loss: 1188.595\n",
            "[epoch: 1, batch:   490] training loss: 1223.073\n",
            "[epoch: 1, batch:   490] <validation 10 random sample> loss: 471.210\n",
            "[epoch: 1, batch:   500] training loss: 968.992\n",
            "[epoch: 1, batch:   500] <validation 10 random sample> loss: 853.569\n",
            "[epoch: 1, batch:   510] training loss: 968.441\n",
            "[epoch: 1, batch:   510] <validation 10 random sample> loss: 589.009\n",
            "[epoch: 1, batch:   520] training loss: 1092.329\n",
            "[epoch: 1, batch:   520] <validation 10 random sample> loss: 765.904\n",
            "[epoch: 1, batch:   530] training loss: 936.838\n",
            "[epoch: 1, batch:   530] <validation 10 random sample> loss: 1119.644\n",
            "[epoch: 1, batch:   540] training loss: 1260.648\n",
            "[epoch: 1, batch:   540] <validation 10 random sample> loss: 913.887\n",
            "[epoch: 1, batch:   550] training loss: 1011.549\n",
            "[epoch: 1, batch:   550] <validation 10 random sample> loss: 793.393\n",
            "[epoch: 1, batch:   560] training loss: 1039.654\n",
            "[epoch: 1, batch:   560] <validation 10 random sample> loss: 1804.051\n",
            "[epoch: 1, batch:   570] training loss: 960.960\n",
            "[epoch: 1, batch:   570] <validation 10 random sample> loss: 1123.133\n",
            "[epoch: 1, batch:   580] training loss: 986.620\n",
            "[epoch: 1, batch:   580] <validation 10 random sample> loss: 1484.518\n",
            "[epoch: 1, batch:   590] training loss: 1254.847\n",
            "[epoch: 1, batch:   590] <validation 10 random sample> loss: 1705.770\n",
            "[epoch: 1, batch:   600] training loss: 1067.251\n",
            "[epoch: 1, batch:   600] <validation 10 random sample> loss: 940.811\n",
            "[epoch: 1, batch:   610] training loss: 1003.809\n",
            "[epoch: 1, batch:   610] <validation 10 random sample> loss: 1084.249\n",
            "[epoch: 1, batch:   620] training loss: 1050.724\n",
            "[epoch: 1, batch:   620] <validation 10 random sample> loss: 1466.218\n",
            "[epoch: 1, batch:   630] training loss: 1147.609\n",
            "[epoch: 1, batch:   630] <validation 10 random sample> loss: 1138.635\n",
            "[epoch: 1, batch:   640] training loss: 1020.582\n",
            "[epoch: 1, batch:   640] <validation 10 random sample> loss: 1766.898\n",
            "[epoch: 1, batch:   650] training loss: 948.254\n",
            "[epoch: 1, batch:   650] <validation 10 random sample> loss: 950.143\n",
            "[epoch: 1, batch:   660] training loss: 967.823\n",
            "[epoch: 1, batch:   660] <validation 10 random sample> loss: 1626.906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([8, 200])) that is different to the input size (torch.Size([7, 200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3ef34479cce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (8) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "fGd8r4eTwbJW",
        "outputId": "b977dc52-e9d8-40b3-dfda-afa0f5cf040a"
      },
      "source": [
        "# network = Network()\r\n",
        "# network.cuda()    \r\n",
        "\r\n",
        "# criterion = nn.MSELoss()\r\n",
        "# optimizer = optim.Adam(network.parameters(), lr=0.0001)\r\n",
        "\r\n",
        "# loss_min = np.inf\r\n",
        "# num_epochs = 10\r\n",
        "\r\n",
        "# start_time = time.time()\r\n",
        "# for epoch in range(1,num_epochs+1):\r\n",
        "    \r\n",
        "#     loss_train = 0\r\n",
        "#     loss_valid = 0\r\n",
        "#     running_loss = 0\r\n",
        "    \r\n",
        "#     network.train()\r\n",
        "#     for step in range(1,len(loader)+1):\r\n",
        "\r\n",
        "#         sample = next(iter(loader))\r\n",
        "#         images, landmarks = sample['image'], sample['label']\r\n",
        "        \r\n",
        "#         images = images.cuda()\r\n",
        "#         landmarks = landmarks.view(landmarks.size(0),-1).cuda() \r\n",
        "        \r\n",
        "#         predictions = network(images)\r\n",
        "        \r\n",
        "#         # clear all the gradients before calculating them\r\n",
        "#         optimizer.zero_grad()\r\n",
        "        \r\n",
        "#         # find the loss for the current step\r\n",
        "#         loss_train_step = criterion(predictions, landmarks)\r\n",
        "        \r\n",
        "#         # calculate the gradients\r\n",
        "#         loss_train_step.backward()\r\n",
        "        \r\n",
        "#         # update the parameters\r\n",
        "#         optimizer.step()\r\n",
        "        \r\n",
        "#         loss_train += loss_train_step.item()\r\n",
        "#         running_loss = loss_train/step\r\n",
        "        \r\n",
        "#         # print_overwrite(step, len(train_loader), running_loss, 'train')\r\n",
        "        \r\n",
        "#     network.eval() \r\n",
        "#     with torch.no_grad():\r\n",
        "        \r\n",
        "#         for step in range(1,  3): #len(loader)+1):\r\n",
        "            \r\n",
        "#             images, landmarks = next(iter(loader))\r\n",
        "        \r\n",
        "#             images = images.cuda()\r\n",
        "#             landmarks = landmarks.view(landmarks.size(0),-1).cuda()\r\n",
        "        \r\n",
        "#             predictions = network(images)\r\n",
        "\r\n",
        "#             # find the loss for the current step\r\n",
        "#             loss_valid_step = criterion(predictions, landmarks)\r\n",
        "\r\n",
        "#             loss_valid += loss_valid_step.item()\r\n",
        "#             running_loss = loss_valid/step\r\n",
        "\r\n",
        "#             print_overwrite(step, len(valid_loader), running_loss, 'valid')\r\n",
        "    \r\n",
        "#     loss_train /= len(train_loader)\r\n",
        "#     loss_valid /= len(valid_loader)\r\n",
        "    \r\n",
        "#     print('\\n--------------------------------------------------')\r\n",
        "#     print('Epoch: {}  Train Loss: {:.4f}  Valid Loss: {:.4f}'.format(epoch, loss_train, loss_valid))\r\n",
        "#     print('--------------------------------------------------')\r\n",
        "    \r\n",
        "#     if loss_valid < loss_min:\r\n",
        "#         loss_min = loss_valid\r\n",
        "#         torch.save(network.state_dict(), '/content/face_landmarks.pth') \r\n",
        "#         print(\"\\nMinimum Validation Loss of {:.4f} at epoch {}/{}\".format(loss_min, epoch, num_epochs))\r\n",
        "#         print('Model Saved\\n')\r\n",
        "     \r\n",
        "# print('Training Complete')\r\n",
        "# print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-372-1d4fbc5f89c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-367-4dadf7cc0547>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcenterCrop_value\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcenterCrop_value\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJIX-wbgMO1C"
      },
      "source": [
        "# find dataset mean and std\r\n",
        "\r\n",
        "# import torch\r\n",
        "# from torch import Tensor\r\n",
        "# from typing import Iterable\r\n",
        "# from fastprogress import progress_bar\r\n",
        "\r\n",
        "# class RunningStatistics:\r\n",
        "#     '''Records mean and variance of the final `n_dims` dimension over other dimensions across items. So collecting across `(l,m,n,o)` sized\r\n",
        "#        items with `n_dims=1` will collect `(l,m,n)` sized statistics while with `n_dims=2` the collected statistics will be of size `(l,m)`.\r\n",
        "#        Uses the algorithm from Chan, Golub, and LeVeque in \"Algorithms for computing the sample variance: analysis and recommendations\":\r\n",
        "#        `variance = variance1 + variance2 + n/(m*(m+n)) * pow(((m/n)*t1 - t2), 2)`\r\n",
        "#        This combines the variance for 2 blocks: block 1 having `n` elements with `variance1` and a sum of `t1` and block 2 having `m` elements\r\n",
        "#        with `variance2` and a sum of `t2`. The algorithm is proven to be numerically stable but there is a reasonable loss of accuracy (~0.1% error).\r\n",
        "#        Note that collecting minimum and maximum values is reasonably innefficient, adding about 80% to the running time, and hence is disabled by default.\r\n",
        "#     '''\r\n",
        "#     def __init__(self, n_dims:int=2, record_range=False):\r\n",
        "#         self._n_dims,self._range = n_dims,record_range\r\n",
        "#         self.n,self.sum,self.min,self.max = 0,None,None,None\r\n",
        "    \r\n",
        "#     def update(self, data:Tensor):\r\n",
        "\r\n",
        "#         data = data.view(*list(data.shape[:-self._n_dims]) + [-1])\r\n",
        "#         with torch.no_grad():\r\n",
        "#             new_n,new_var,new_sum = data.shape[-1],data.var(-1),data.sum(-1)\r\n",
        "#             if self.n == 0:\r\n",
        "#                 self.n = new_n\r\n",
        "#                 self._shape = data.shape[:-1]\r\n",
        "#                 self.sum = new_sum\r\n",
        "#                 self._nvar = new_var.mul_(new_n)\r\n",
        "#                 if self._range:\r\n",
        "#                     self.min = data.min(-1)[0]\r\n",
        "#                     self.max = data.max(-1)[0]\r\n",
        "#             else:\r\n",
        "#                 # assert data.shape[:-1] == self._shape, f\"Mismatched shapes, expected {self._shape} but got {data.shape[:-1]}.\"\r\n",
        "#                 ratio = self.n / new_n\r\n",
        "#                 t = (self.sum / ratio).sub_(new_sum).pow_(2)\r\n",
        "#                 self._nvar.add_(new_n, new_var).add_(ratio / (self.n + new_n), t)\r\n",
        "#                 self.sum.add_(new_sum)\r\n",
        "#                 self.n += new_n\r\n",
        "#                 if self._range:\r\n",
        "#                     self.min = torch.min(self.min, data.min(-1)[0])\r\n",
        "#                     self.max = torch.max(self.max, data.max(-1)[0])\r\n",
        "\r\n",
        "#     @property\r\n",
        "#     def mean(self): return self.sum / self.n if self.n > 0 else None\r\n",
        "#     @property\r\n",
        "#     def var(self): return self._nvar / self.n if self.n > 0 else None\r\n",
        "#     @property\r\n",
        "#     def std(self): return self.var.sqrt() if self.n > 0 else None\r\n",
        "\r\n",
        "#     def __repr__(self):\r\n",
        "#         def _fmt_t(t:Tensor):\r\n",
        "#             if t.numel() > 5: return f\"tensor of ({','.join(map(str,t.shape))})\"\r\n",
        "#             def __fmt_t(t:Tensor):\r\n",
        "#                 return '[' + ','.join([f\"{v:.3g}\" if v.ndim==0 else __fmt_t(v) for v in t]) + ']'\r\n",
        "#             return __fmt_t(t)\r\n",
        "#         rng_str = f\", min={_fmt_t(self.min)}, max={_fmt_t(self.max)}\" if self._range else \"\"\r\n",
        "#         return f\"RunningStatistics(n={self.n}, mean={_fmt_t(self.mean)}, std={_fmt_t(self.std)}{rng_str})\"\r\n",
        "\r\n",
        "# def collect_stats(items:Iterable, n_dims:int=2, record_range:bool=False):\r\n",
        "#     stats = RunningStatistics(n_dims, record_range)\r\n",
        "#     for it in progress_bar(items.next()):\r\n",
        "#         it = it.float()\r\n",
        "#         if hasattr(it, 'data'):\r\n",
        "#             stats.update(it.data)\r\n",
        "#         else:\r\n",
        "#             stats.update(it)\r\n",
        "#     return stats\r\n",
        "\r\n",
        "# dd = RunningStatistics\r\n",
        "# stats = collect_stats(dataiter)\r\n",
        "# stats\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZXTf5UJDsbO",
        "outputId": "37e138e7-9b65-4653-d0f3-ab3d22356726"
      },
      "source": [
        "# stats.mean.mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5057, 0.5057, 0.5057])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGmx2VtMJKQi",
        "outputId": "be0872a5-6dcd-43c5-e056-bc4732399513"
      },
      "source": [
        "# stats.std.mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1902, 0.1902, 0.1902])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOCxit_OJ787"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}