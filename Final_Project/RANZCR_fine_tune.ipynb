{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RANZCR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Machine-Learning-Course/blob/main/Final_Project/RANZCR_fine_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTBBnTu6fgXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2974c94-3290-4847-8353-3b43345ba520"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CiPXKgnKjBy"
      },
      "source": [
        "# # # # trainset\r\n",
        "# !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1612356291&Signature=Y0prr2JieE4gY4AM9EwN3MiMCxiaLjN2t5v6pD%2Fn08VSNiJWS2iNK%2FQAaQOeRAnH578jfJmQA8hdCRgLL6yz2NUuXRz3Vey0DlcexHiEQLn5eqUeDlFx9Z76zxf6KNd%2BLxxwofJzbJrwI2OMoC2tb26jlASakwqFUaX14f5U9pJ2Ct9Nw6%2Bf515mtCUtmX1qroNRLXjWuUvFRT%2FmZQKj54raaqr2%2BhTYSYYEB8tuEDAi11p9U6tniCKX%2B%2BEbV%2B4RLCGZQRjtlt5%2FfadwcVLbSpcBp%2BrNaMZEOz2A8jwJNpmWXHemo%2FARNnobvn7WIKvSVHDrZ%2FZ61gbEWVaOk0xz5w%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.zip'\r\n",
        "\r\n",
        "# # # train_tfrecords\r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train_tfrecords.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611835011&Signature=OBxBwfMr9c0gB7Qmiiv9lGIHSqsT2ocsodWh1H56xb%2FYMBjLkiPKxiDXMBPnvOnaUGhMmKTmlpK06O8721DFO1hCNrq9757gZrxaVpm4400ABhzZ86NgLyLfC7Zse6GUlByeDrdd2Dk6KwI%2BjHFPg4TFFov3DW13I2%2FKw9h22tNbssdkfTA7OZgll1EW9Ynh6g%2F2ULQrmTtjkfdLbObPyniLEA5vHLXnK0ySw%2FaNS%2BCICHgGf4ECYqmrdWvzm8uDBrhrDs%2BwEwyMVTa4ZqnI0AS8FoMHexQV5yxbfUmihUDArft4QXrSnyCakAjaPHbknW2gyBfkmE%2FP0AHXAMx7Cg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain_tfrecords.zip'\r\n",
        "\r\n",
        "# # # # testset\r\n",
        "# # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611411985&Signature=SPlBo05ncQEsd8RLzLUOCGhZ49kM9hcob5WJ1vdJHtGtL6a663HEdtgbwO3mIuv7jGtZYQltdUDZv867XtyOGPuLThK1rKdebC3jRq5DPYnIQPK%2BJ0JX%2FLcTnGiuRgPsxevW0vfjlBsEmJzYHr%2BXsKU6TdOHMaAwyCSX1JVMtO32C3BrgPNujkQ7HiTJ2C7H5bK7mB1Gm0Li%2Bg2wV2IhFl6%2FqW0CvDf3v3eBp9yS8Xt4w18VV5hkebAlCtXts8VU%2BxIgGy8nwIoJSq2vsSUAqx%2BfsuZkOOLfL0YnQ9ziqinMQSuAv8TXcGUhmlz5NS%2Bmmu%2BeRsPbOW9YJw4nkixsow%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest.zip'\r\n",
        "\r\n",
        "# # # # test_tfrecords\r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/test_tfrecords.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611412043&Signature=qChPWagoJ3ee9%2FErHTtluS1ojjzeWYALCFY%2BZ9TlU22ED2wIe3p7N98k6RDN3re7EKft5m%2FkeHszfURu59kwAA52o7F8pkvSMXoiuRctQGue4zNza4rKmVLzyvcqbRe7KmEDqiKtT2%2BY2UPaXxc0Yk0fHqqFe%2FZSbP7mqtXFUZHoGv8vW%2BS7Y4DRMXtPNbh5tBX9vHeDNJQ2UhIDOJwzfJCNWsFX5LZBohl7%2BjtzkGee%2FWPCel%2FCbdcddj%2BAvq1CMsRx8vpxRxNnubFCxTY8daCkZm4%2Bi%2FTZl92alLXWeaWda2RcidU2X7oGLbgdYhv3fzSGbBgM18VbJTDO7L71qg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest_tfrecords.zip'\r\n",
        "\r\n",
        "# # # # train.csv\r\n",
        "# !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1612356318&Signature=lh2uk0xwhvoC1FXe2IXtIRGKI4Oj%2FW%2F1Vdir6z%2FUbcCD6HsUCsGJu0eZmiUu1EQYDxv%2B6QWeA1Z5tev2fJTAsp9fAuSkbMRQfCclKgvV5bH5lcBdGkCAQAye6gMUIb6%2BXVMtSS6gQnCNjLisommB6%2BYqVeFcnATyLRxplrNPdxoQYMnOgJQKDWPqAvH0HAoYRzJVat%2BB19DXVFyQQHXc8Hdwv537NLHwDLNuI3F%2BM40PjpuIGPxEcRqVy%2Bj0RGFG5A1%2FgeylicvBq7j0%2FJ0ixo5nix%2FK1GyY7n%2FTOdIKV8rGYNrV1zhi2oGb2SoODfJ1FrmcGu6ikcYetp5ixDlOZg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip'\r\n",
        "\r\n",
        "# # # # submission sample\r\n",
        "# # # !wget \"https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/data?select=sample_submission.csv\"\r\n",
        "\r\n",
        "# # # # train annotations \r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train_annotations.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611835498&Signature=DftuTDD7S8H3eTfh%2FLQA50BWtL%2BSATrjxebLTtDXUMN9g4XyzYqCLy6C1pzb9ilL9tS23LI5tUf69e%2B5DxhY2SZBwyQXGss8H69%2F8yewJee93tSn1Asl3z19ExCzGji0rOmritXmVNuLhzApyK6KOw86NfL5pGrXhuBo%2FYSwPDsLpdnYcLsh7m09xfgjtci%2FomGFy3j6hhZxIJyYOwol9wYRWlOFFEtxq0lQ1l8BSv6O6Z1Yl9WV%2FzIV%2FJwA1YUYtHpeAENoGutDAfOAS7ogALme3KOgDMsK4Zv3uJ9Ofkamhz1sMM8g61gdug%2BBpKZY0xmJrrsLQ4NfEL09zRUmaA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain_annotations.csv.zip'\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3f4srgdOJ53"
      },
      "source": [
        "# !mkdir /content/trainset\r\n",
        "# !mkdir /content/trainset/data/\r\n",
        "# !mkdir /content/trainset/data/1/\r\n",
        "# !unzip '/content/train.zip' -d /content/trainset/data/1/\r\n",
        "# # # # !unzip '/content/train_tfrecords.zip' -d /content/trainset/tf_records/\r\n",
        "# # # # !unzip '/content/train_annotations.csv.zip' -d /content/trainset/\r\n",
        "# !unzip '/content/train.csv.zip' -d /content/trainset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvDL9xh2Qc6N"
      },
      "source": [
        "# !mkdir /content/testset\r\n",
        "# !unzip '/content/test.zip' -d /content/testset/data\r\n",
        "# !unzip '/content/test_tfrecords.zip' -d /content/testset/test_tfrecords/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-LgJKyRBziW"
      },
      "source": [
        "# !rm /content/test.zip\r\n",
        "# !rm /content/test_tfrecords.zip\r\n",
        "# !rm /content/train.csv.zip\r\n",
        "# !rm /content/train.zip\r\n",
        "# !rm /content/train_annotations.csv.zip\r\n",
        "# !rm /content/train_tfrecords.zip\r\n",
        "# !rm -rf /content/trainset/data/1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPQAQU7ncDsr"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "# sample_submission = pd.read_csv('/content/sample_submission.csv')\r\n",
        "# sample_submission.head()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikRE9MDNnQGK"
      },
      "source": [
        "train_csv = pd.read_csv('/content/trainset/train.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgM8GN2e1izJ"
      },
      "source": [
        "def sampling(trainset, sample_per_class):\r\n",
        "  \r\n",
        "\r\n",
        "    index_list = []\r\n",
        "    validation_index_list = []\r\n",
        "    threshold = np.full((12, ), sample_per_class)\r\n",
        "    for index, row in train_csv.iterrows():\r\n",
        "        sample = row[1:-1].values\r\n",
        "        flag = True\r\n",
        "        for i in range(11):\r\n",
        "            if threshold[i] > 0 :\r\n",
        "              if sample[i] == 1:\r\n",
        "                flag = False\r\n",
        "                threshold[i] -= 1\r\n",
        "                index_list.append(index)\r\n",
        "                break\r\n",
        "                \r\n",
        "              else:\r\n",
        "                pass  \r\n",
        "            else:\r\n",
        "              pass\r\n",
        "        if flag:\r\n",
        "          if threshold[11] > 0:\r\n",
        "            threshold[11] -= 1  \r\n",
        "            index_list.append(index) \r\n",
        "        else:\r\n",
        "            validation_index_list.append(index)\r\n",
        "\r\n",
        "\r\n",
        "    return index_list, validation_index_list\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLVFb6FLPtEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd23759-0d7a-4152-ebd5-acaef9c9ebbd"
      },
      "source": [
        "len(train_csv)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UdhB_tN9XpN",
        "outputId": "3de0ea07-b428-4139-a19f-4794fc4542fb"
      },
      "source": [
        "sampled_index, validation_index = sampling(train_csv, 700)\r\n",
        "validation_names =train_csv.iloc[validation_index, :]\r\n",
        "print(len(validation_names))\r\n",
        "images_name =train_csv.iloc[sampled_index, :]\r\n",
        "len(images_name)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6910"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLHK1Y7rwgby"
      },
      "source": [
        "from __future__ import print_function, division\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import torchvision\r\n",
        "from skimage import io, transform\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUnroASw1rgR"
      },
      "source": [
        "# we calculate dataset mean and standard derivation only once \r\n",
        "\r\n",
        "\r\n",
        "# from tqdm import tqdm \r\n",
        "\r\n",
        "# dataset = datasets.ImageFolder('/content/trainset/data', transform=transforms.Compose([transforms.Resize((512, 512)),\r\n",
        "#                                                                                        transforms.ToTensor()]))\r\n",
        "\r\n",
        "# loader = torch.utils.data.DataLoader(dataset,\r\n",
        "#                          batch_size=10,\r\n",
        "#                          num_workers=0,\r\n",
        "#                          shuffle=False)\r\n",
        "\r\n",
        "# var = 0.0\r\n",
        "# mean = 0.0\r\n",
        "# for i, data in tqdm(enumerate(loader)):\r\n",
        "#     images = data[0]\r\n",
        "#     batch_samples = images.size(0) \r\n",
        "#     images = images.view(batch_samples, images.size(1), -1)\r\n",
        "#     mean += images.mean(2).sum(0)\r\n",
        "#     var += ((images - mean.unsqueeze(1))**2).sum([0,2])\r\n",
        "# std = torch.sqrt(var / (len(loader.dataset)*224*224))\r\n",
        "# mean = mean / len(loader.dataset)\r\n",
        "\r\n",
        "# print('dataset mean: ', mean)\r\n",
        "# print('dataset std: ', std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaxSOFwmBeWS"
      },
      "source": [
        "# these results are calculated using above cell \r\n",
        "\r\n",
        "mean = np.array([0.4823, 0.4823, 0.4823])\r\n",
        "std = np.array([0.191473164, 0.191473164, 0.191473164])\r\n",
        "\r\n",
        "\r\n",
        "# mean = np.array([0.4823])\r\n",
        "# std = np.array([19147.3164])\r\n",
        "# mean = np.array([0.4823])\r\n",
        "# std = np.array([0.5])\r\n",
        "# mean = np.array([0.5057, 0.5057, 0.5057])\r\n",
        "# std = np.array([0.1902, 0.1902, 0.1902])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD6dPyTlt_lR"
      },
      "source": [
        "from PIL import Image\r\n",
        "\r\n",
        "\r\n",
        "class RANZCRDataset(Dataset):\r\n",
        "\r\n",
        "\r\n",
        "    def __init__(self, csv_file='/content/trainset/train.csv', root_dir='/content/trainset/data/1', transform=transform, images_name=None):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            csv_file (string): Path to the csv file with annotations.\r\n",
        "            root_dir (string): Directory with all the images.\r\n",
        "            transform (callable, optional): Optional transform to be applied\r\n",
        "                on a sample.\r\n",
        "        \"\"\"\r\n",
        "        self.Images_name = images_name\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.transform = transform\r\n",
        "        \r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.Images_name)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if torch.is_tensor(idx):\r\n",
        "            idx = idx.tolist()\r\n",
        "\r\n",
        "        img_name = os.path.join(self.root_dir,\r\n",
        "                                self.Images_name.iloc[idx, 0])\r\n",
        "        image = Image.open(img_name + '.jpg').convert('RGB')\r\n",
        "        labels = self.Images_name.iloc[idx, 1:-1].values\r\n",
        "        labels = labels.astype(np.int)\r\n",
        "        labels = torch.from_numpy(labels)\r\n",
        "        sample = {'image': image, 'label': labels }\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "\r\n",
        "          sample['image'] = self.transform(sample['image'])\r\n",
        "\r\n",
        "\r\n",
        "        return sample"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgSZrpo8RAxk"
      },
      "source": [
        "import torch\r\n",
        "from torchvision import datasets, transforms\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "def load_data(csv_file='/content/trainset/train.csv', data_dir='/content/trainset/data/1'):\r\n",
        "\r\n",
        "  transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "                                  transforms.Resize((1024, 1024)),\r\n",
        "                                  transforms.CenterCrop(904),\r\n",
        "                                  transforms.Normalize(mean, std)])\r\n",
        "\r\n",
        "\r\n",
        "  trainset = RANZCRDataset(csv_file=csv_file,\r\n",
        "                                      root_dir=data_dir, transform=transform, images_name=images_name)\r\n",
        "\r\n",
        "\r\n",
        "  validation = RANZCRDataset(csv_file=csv_file,\r\n",
        "                                    root_dir=data_dir, transform=transform, images_name=validation_names)\r\n",
        "  \r\n",
        "\r\n",
        "  \r\n",
        "  return trainset, validation\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Tocrklk9gY"
      },
      "source": [
        "# train_data_loader = torch.utils.data.DataLoader(trainset,\r\n",
        "#                                           batch_size=8,\r\n",
        "#                                           shuffle=True,\r\n",
        "#                                           num_workers=0)\r\n",
        "\r\n",
        "\r\n",
        "# validation_data_loader = torch.utils.data.DataLoader(validation,\r\n",
        "#                                           batch_size=8,\r\n",
        "#                                           shuffle=True,\r\n",
        "#                                           num_workers=0)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8muYGHBGwZen"
      },
      "source": [
        "# def imshow(img):\r\n",
        "#     npimg = img.numpy()\r\n",
        "#     npimg = ((npimg * std[0]) + mean[0]) # unnormalize\r\n",
        "#     plt.imshow((np.transpose(npimg, (1, 2, 0)) * 255).astype(np.uint8))\r\n",
        "#     plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# # get some random training images\r\n",
        "# dataiter = iter(train_data_loader)\r\n",
        "# sample = dataiter.next()\r\n",
        "# print(sample['image'].shape)\r\n",
        "# imshow(torchvision.utils.make_grid(sample['image']))\r\n",
        "# print(sample['label'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dpyq8uYr8-7"
      },
      "source": [
        "model = torchvision.models.resnet152(pretrained=False, progress=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oFre0HvsMRj"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpItSJloHImE"
      },
      "source": [
        "for param in model.parameters():\r\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLymbGLgMpu_"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F \r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self, l1=512, l2=256, c1=3):\r\n",
        "    super(Net, self).__init__()\r\n",
        "    self.model = model\r\n",
        "    self.conv1 = nn.Conv2d(3, c1, 5)\r\n",
        "    self.conv2 = nn.Conv2d(c1, 3, 1)\r\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\r\n",
        "    self.sigmoid = nn.Sigmoid()\r\n",
        "    self.fc1 = nn.Linear(1000, l1)\r\n",
        "    self.fc2 = nn.Linear(l1, l2)\r\n",
        "    self.fc_final = nn.Linear(l2, 11)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    x = self.pool2(F.relu(self.conv1(x)))\r\n",
        "    x = self.pool2(F.relu(self.conv2(x)))\r\n",
        "    x = self.model(x)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = F.relu(self.fc2(x))\r\n",
        "    x = self.sigmoid(self.fc_final(x))\r\n",
        "    return x\r\n",
        "\r\n",
        "# Network = Net()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_7y4DPkHgjH"
      },
      "source": [
        "# def count_parameters(model):\r\n",
        "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "# print(count_parameters(model))\r\n",
        "# print(count_parameters(Network))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Wb3uf0gF3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c896167b-690b-4cb9-aacc-28c766f96e06"
      },
      "source": [
        "\r\n",
        "# Network.load_state_dict(torch.load('/content/drive/MyDrive/model.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DrXdrMNoE6s"
      },
      "source": [
        "# ####################################\r\n",
        "# !pip install ray\r\n",
        "# !pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2jjjLlPnfOl"
      },
      "source": [
        "\r\n",
        "from functools import partial\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import random_split\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from ray import tune\r\n",
        "from ray.tune import CLIReporter\r\n",
        "from ray.tune.schedulers import ASHAScheduler\r\n",
        "import tensorboardX"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSY9uhoeWodl"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "def roc_auc_compute_fn(y_preds, y_targets):\r\n",
        "\r\n",
        "    \r\n",
        "    try:\r\n",
        "        from sklearn.metrics import roc_auc_score\r\n",
        "    except ImportError:\r\n",
        "        raise RuntimeError(\"This contrib module requires sklearn to be installed.\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    y_true = y_targets.cpu().detach().numpy()\r\n",
        "    y_pred = y_preds.cpu().detach().numpy()\r\n",
        "    try:\r\n",
        "      return roc_auc_score(y_pred, y_true, average='micro')\r\n",
        "    except ValueError:\r\n",
        "      return None\r\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN88p-B3m3PU"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "def train_ranzcr(config, checkpoint_dir=None, data_dir=None):\r\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\r\n",
        "\r\n",
        "    device = \"cpu\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = \"cuda:0\"\r\n",
        "        if torch.cuda.device_count() > 1:\r\n",
        "            net = nn.DataParallel(net)\r\n",
        "    net.to(device)\r\n",
        "\r\n",
        "    criterion = nn.BCELoss()\r\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=config[\"wd\"])\r\n",
        "\r\n",
        "    if checkpoint_dir:\r\n",
        "        model_state, optimizer_state = torch.load(\r\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\r\n",
        "        net.load_state_dict(model_state)\r\n",
        "        optimizer.load_state_dict(optimizer_state)\r\n",
        "\r\n",
        "    trainset, testset = load_data(data_dir)\r\n",
        "\r\n",
        "    test_abs = int(len(trainset) * 0.8)\r\n",
        "    train_subset, val_subset = random_split(\r\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\r\n",
        "\r\n",
        "    trainloader = torch.utils.data.DataLoader(\r\n",
        "        train_subset,\r\n",
        "        batch_size=int(config[\"batch_size\"]),\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=8)\r\n",
        "    valloader = torch.utils.data.DataLoader(\r\n",
        "        val_subset,\r\n",
        "        batch_size=int(config[\"batch_size\"]),\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=8)\r\n",
        "\r\n",
        "    for epoch in range(10):  # loop over the dataset multiple times\r\n",
        "        running_loss = 0.0\r\n",
        "        epoch_steps = 0\r\n",
        "        for i, data in enumerate(trainloader, 0):\r\n",
        "            # get the inputs; data is a list of [inputs, labels]\r\n",
        "            inputs, labels = data['image'].float(), data['label'].float()\r\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "            # zero the parameter gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # forward + backward + optimize\r\n",
        "            outputs = net(inputs)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            # print statistics\r\n",
        "            running_loss += loss.item()\r\n",
        "            epoch_steps += 1\r\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\r\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\r\n",
        "                                                running_loss / epoch_steps))\r\n",
        "                running_loss = 0.0\r\n",
        "\r\n",
        "        # Validation loss\r\n",
        "        val_loss = 0.0\r\n",
        "        val_steps = 0\r\n",
        "        total = 0\r\n",
        "        correct = 0\r\n",
        "        accuracy = 0\r\n",
        "        batch_counter = 0\r\n",
        "        for i, data in enumerate(valloader, 0):\r\n",
        "            with torch.no_grad():\r\n",
        "                inputs, labels = data['image'].float(), data['label'].float()\r\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "                outputs = net(inputs)\r\n",
        "                # _, predicted = torch.max(outputs.data, 1)\r\n",
        "                # total += labels.size(0)\r\n",
        "                # correct += (predicted == labels).sum().item()\r\n",
        "                # my_validation_outputs = (outputs > 0.5)\r\n",
        "                # print('------------------------------------------------------------------------------')\r\n",
        "                # print(labels)\r\n",
        "                # print(my_validation_outputs)\r\n",
        "                # print('------------------------------------------------------------------------------')\r\n",
        "                # accuracy += auc_s(labels, my_validation_outputs)\r\n",
        "                # batch_counter += 1\r\n",
        "                accuracy += roc_auc_compute_fn(labels, outputs)\r\n",
        "                batch_counter += 1\r\n",
        "\r\n",
        "                loss = criterion(outputs, labels)\r\n",
        "                val_loss += loss.cpu().numpy()\r\n",
        "                val_steps += 1\r\n",
        "\r\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\r\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\r\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\r\n",
        "\r\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=(accuracy / batch_counter))\r\n",
        "    print(\"Finished Training\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCprU3xDng_X"
      },
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\r\n",
        "    trainset, testset = load_data()\r\n",
        "\r\n",
        "    testloader = torch.utils.data.DataLoader(\r\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2)\r\n",
        "\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    batch_counter_test = 0\r\n",
        "    accuracy_test = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in testloader:\r\n",
        "            images, labels = data['image'].float(), data['label'].float()\r\n",
        "            images, labels = images.to(device), labels.to(device)\r\n",
        "            outputs = net(images)\r\n",
        "            # _, predicted = torch.max(outputs.data, 1)\r\n",
        "            # total += labels.size(0)\r\n",
        "            # correct += (predicted == labels).sum().item()\r\n",
        "            # my_test_outputs = (outputs > 0.5)\r\n",
        "            # accuracy_test += accuracy_score(labels, my_test_outputs)\r\n",
        "            # batch_counter_test += 1\r\n",
        "            accuracy_test += roc_auc_compute_fn(labels, outputs)\r\n",
        "            batch_counter_test += 1\r\n",
        "\r\n",
        "\r\n",
        "    return accuracy_test / batch_counter_test"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4x9x0Gvnl1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56472481-7fb7-4e08-be64-857d13901c95"
      },
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\r\n",
        "    data_dir = os.path.abspath(\"/content/trainset/data\")\r\n",
        "    load_data(data_dir)\r\n",
        "    config = {\r\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(5, 9)),\r\n",
        "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(4, 9)),\r\n",
        "        \"lr\": tune.loguniform(1e-5, 1e-1),\r\n",
        "        \"wd\": tune.loguniform(1e-6, 1e-2),\r\n",
        "        \"c1\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 6)),\r\n",
        "        \"batch_size\": tune.choice([4, 8, 16])\r\n",
        "    }\r\n",
        "    scheduler = ASHAScheduler(\r\n",
        "        metric=\"loss\",\r\n",
        "        mode=\"min\",\r\n",
        "        max_t=max_num_epochs,\r\n",
        "        grace_period=1,\r\n",
        "        reduction_factor=2)\r\n",
        "    reporter = CLIReporter(\r\n",
        "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\r\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\r\n",
        "    result = tune.run(\r\n",
        "        partial(train_ranzcr, data_dir=data_dir),\r\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\r\n",
        "        config=config,\r\n",
        "        num_samples=num_samples,\r\n",
        "        scheduler=scheduler,\r\n",
        "        progress_reporter=reporter)\r\n",
        "\r\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\r\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\r\n",
        "    print(\"Best trial final validation loss: {}\".format(\r\n",
        "        best_trial.last_result[\"loss\"]))\r\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\r\n",
        "        best_trial.last_result[\"accuracy\"]))\r\n",
        "\r\n",
        "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\r\n",
        "    device = \"cpu\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = \"cuda:0\"\r\n",
        "        if gpus_per_trial > 1:\r\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\r\n",
        "    best_trained_model.to(device)\r\n",
        "\r\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\r\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\r\n",
        "        best_checkpoint_dir, \"checkpoint\"))\r\n",
        "    best_trained_model.load_state_dict(model_state)\r\n",
        "\r\n",
        "    test_acc = test_accuracy(best_trained_model, device)\r\n",
        "    torch.save(best_trained_model.state_dict(), '/content/drive/MyDrive/model_second_train.pth')\r\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # You can change the number of GPUs per trial here:\r\n",
        "    main(num_samples=20, max_num_epochs=10, gpus_per_trial=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 17:31:23,419\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "2021-01-31 17:31:26,175\tWARNING experiment.py:285 -- No name detected on trainable. Using DEFAULT.\n",
            "2021-01-31 17:31:26,177\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n",
            "2021-01-31 17:31:36,708\tWARNING worker.py:1034 -- Warning: The actor ImplicitFunc has size 243588994 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n",
            "2021-01-31 17:31:36,985\tWARNING util.py:142 -- The `start_trial` operation took 5.517 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2/2 CPUs, 0.5/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_17-31-27\n",
            "Number of trials: 1/20 (1 RUNNING)\n",
            "+---------------------+----------+-------+--------------+------+------+------+------------+-------------+\n",
            "| Trial name          | status   | loc   |   batch_size |   c1 |   l1 |   l2 |         lr |          wd |\n",
            "|---------------------+----------+-------+--------------+------+------+------+------------+-------------|\n",
            "| DEFAULT_2704b_00000 | RUNNING  |       |            4 |   32 |  128 |   64 | 0.00795112 | 5.19815e-05 |\n",
            "+---------------------+----------+-------+--------------+------+------+------+------------+-------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_2704b_00000:\n",
            "  accuracy: 0.7907531401500534\n",
            "  date: 2021-01-31_17-44-51\n",
            "  done: false\n",
            "  experiment_id: 4f1bf3a5b8be479f8e6ba9b2d21fee8f\n",
            "  hostname: f6b7f9eeb497\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.41830991923464517\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 8162\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 791.4871311187744\n",
            "  time_this_iter_s: 791.4871311187744\n",
            "  time_total_s: 791.4871311187744\n",
            "  timestamp: 1612115091\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 2704b_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.41830991923464517\n",
            "Resources requested: 2/2 CPUs, 0.5/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_17-31-27\n",
            "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+---------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |         lr |          wd |    loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+---------+------------+----------------------|\n",
            "| DEFAULT_2704b_00000 | RUNNING  | 172.28.0.2:8162 |            4 |   32 |  128 |   64 | 0.00795112 | 5.19815e-05 | 0.41831 |   0.790753 |                    1 |\n",
            "| DEFAULT_2704b_00001 | PENDING  |                 |            4 |   16 |   32 |   16 | 0.0011616  | 0.000323306 |         |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 17:44:53,953\tWARNING util.py:142 -- The `process_trial_save` operation took 1.819 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_2704b_00000:\n",
            "  accuracy: 0.7979017089821241\n",
            "  date: 2021-01-31_17-58-11\n",
            "  done: false\n",
            "  experiment_id: 4f1bf3a5b8be479f8e6ba9b2d21fee8f\n",
            "  hostname: f6b7f9eeb497\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.41818273541210704\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 8162\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1591.1842095851898\n",
            "  time_this_iter_s: 799.6970784664154\n",
            "  time_total_s: 1591.1842095851898\n",
            "  timestamp: 1612115891\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 2704b_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.41818273541210704 | Iter 1.000: -0.41830991923464517\n",
            "Resources requested: 2/2 CPUs, 0.5/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_17-31-27\n",
            "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |         lr |          wd |     loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+----------+------------+----------------------|\n",
            "| DEFAULT_2704b_00000 | RUNNING  | 172.28.0.2:8162 |            4 |   32 |  128 |   64 | 0.00795112 | 5.19815e-05 | 0.418183 |   0.797902 |                    2 |\n",
            "| DEFAULT_2704b_00001 | PENDING  |                 |            4 |   16 |   32 |   16 | 0.0011616  | 0.000323306 |          |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 17:58:13,584\tWARNING util.py:142 -- The `process_trial_save` operation took 1.794 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_2704b_00000:\n",
            "  accuracy: 0.8107595815822415\n",
            "  date: 2021-01-31_18-11-33\n",
            "  done: false\n",
            "  experiment_id: 4f1bf3a5b8be479f8e6ba9b2d21fee8f\n",
            "  hostname: f6b7f9eeb497\n",
            "  iterations_since_restore: 3\n",
            "  loss: 0.40520729516455206\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 8162\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2392.9105520248413\n",
            "  time_this_iter_s: 801.7263424396515\n",
            "  time_total_s: 2392.9105520248413\n",
            "  timestamp: 1612116693\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: 2704b_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 7.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.41818273541210704 | Iter 1.000: -0.41830991923464517\n",
            "Resources requested: 2/2 CPUs, 0.5/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_17-31-27\n",
            "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+----------+------------+----------------------+\n",
            "| Trial name          | status   | loc             |   batch_size |   c1 |   l1 |   l2 |         lr |          wd |     loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+----------+------------+----------------------|\n",
            "| DEFAULT_2704b_00000 | RUNNING  | 172.28.0.2:8162 |            4 |   32 |  128 |   64 | 0.00795112 | 5.19815e-05 | 0.405207 |    0.81076 |                    3 |\n",
            "| DEFAULT_2704b_00001 | PENDING  |                 |            4 |   16 |   32 |   16 | 0.0011616  | 0.000323306 |          |            |                      |\n",
            "+---------------------+----------+-----------------+--------------+------+------+------+------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 18:11:35,744\tWARNING util.py:142 -- The `process_trial_save` operation took 1.840 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjwmUvBRYqR6"
      },
      "source": [
        "# for epoch in range(20):\r\n",
        "\r\n",
        "#   running_loss = 0.0\r\n",
        "#   best_validation_auc_score = 0\r\n",
        "\r\n",
        "#   for i, data in enumerate(train_data_loader, 0):\r\n",
        "    \r\n",
        "\r\n",
        "#     inputs = data['image'].float()\r\n",
        "#     label = data['label'].float()\r\n",
        "#     optimizer.zero_grad()\r\n",
        "#     outputs = Network(inputs)\r\n",
        "#     loss = loss_function(outputs, label)\r\n",
        "#     loss.backward()\r\n",
        "#     optimizer.step()\r\n",
        "\r\n",
        "#     auc_score = roc_auc_compute_fn(outputs, label)\r\n",
        "#     running_loss += loss.item()\r\n",
        "#     if (i % 10 == 0) and (i > 9):\r\n",
        "#       print('[epoch: %d, batch: %5d] training loss: %.3f training auc score: %.3f' %( epoch + 1, i, (running_loss/10), auc_score))\r\n",
        "      \r\n",
        "#       dataiter = iter(validation_data_loader)\r\n",
        "#       sample = dataiter.next()\r\n",
        "#       validation_inputs = sample['image'].float()\r\n",
        "#       validation_label = sample['label'].float()\r\n",
        "#       validation_outputs = Network(validation_inputs)\r\n",
        "#       validation_loss = loss_function(validation_outputs, validation_label)\r\n",
        "#       validation_auc_score = roc_auc_compute_fn(validation_outputs, validation_label)\r\n",
        "\r\n",
        "#       print('[epoch: %d, batch: %5d] <validation 10 random sample> loss: %.3f , auc score: %.3f' %( epoch + 1, i, validation_loss, validation_auc_score))\r\n",
        "\r\n",
        "\r\n",
        "#       running_loss = 0.0\r\n",
        "\r\n",
        "#   try:\r\n",
        "#     if validation_auc_score > best_validation_auc_score:\r\n",
        "#       torch.save(Network.state_dict(), '/content/drive/MyDrive/model_second_train.pth')\r\n",
        "#       best_validation_auc_score = validation_auc_score\r\n",
        "#   except ValueError:\r\n",
        "#     pass\r\n",
        "  \r\n",
        "    \r\n",
        "# print('Finished Training Network')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQkE8mE4ssFm"
      },
      "source": [
        "# # Quick evaluation \r\n",
        "\r\n",
        "# # get some random training images\r\n",
        "# dataiter = iter(train_data_loader)\r\n",
        "# sample = dataiter.next()\r\n",
        "# inputs = sample['image'].float()\r\n",
        "# label = sample['label'].float()\r\n",
        "# print(inputs.shape)\r\n",
        "# batch_predicted_values = Network(inputs)\r\n",
        "# imshow(torchvision.utils.make_grid(sample['image']))\r\n",
        "# print(sample['label'])\r\n",
        "# print(batch_predicted_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnhhfYNZJbhc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}