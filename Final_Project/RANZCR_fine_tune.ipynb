{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RANZCR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Machine-Learning-Course/blob/main/Final_Project/RANZCR_fine_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTBBnTu6fgXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b049aa3-ae63-4981-8bc3-7863e1a63e03"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CiPXKgnKjBy"
      },
      "source": [
        "# # # # trainset\r\n",
        "# !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1612356291&Signature=Y0prr2JieE4gY4AM9EwN3MiMCxiaLjN2t5v6pD%2Fn08VSNiJWS2iNK%2FQAaQOeRAnH578jfJmQA8hdCRgLL6yz2NUuXRz3Vey0DlcexHiEQLn5eqUeDlFx9Z76zxf6KNd%2BLxxwofJzbJrwI2OMoC2tb26jlASakwqFUaX14f5U9pJ2Ct9Nw6%2Bf515mtCUtmX1qroNRLXjWuUvFRT%2FmZQKj54raaqr2%2BhTYSYYEB8tuEDAi11p9U6tniCKX%2B%2BEbV%2B4RLCGZQRjtlt5%2FfadwcVLbSpcBp%2BrNaMZEOz2A8jwJNpmWXHemo%2FARNnobvn7WIKvSVHDrZ%2FZ61gbEWVaOk0xz5w%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.zip'\r\n",
        "\r\n",
        "# # # train_tfrecords\r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train_tfrecords.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611835011&Signature=OBxBwfMr9c0gB7Qmiiv9lGIHSqsT2ocsodWh1H56xb%2FYMBjLkiPKxiDXMBPnvOnaUGhMmKTmlpK06O8721DFO1hCNrq9757gZrxaVpm4400ABhzZ86NgLyLfC7Zse6GUlByeDrdd2Dk6KwI%2BjHFPg4TFFov3DW13I2%2FKw9h22tNbssdkfTA7OZgll1EW9Ynh6g%2F2ULQrmTtjkfdLbObPyniLEA5vHLXnK0ySw%2FaNS%2BCICHgGf4ECYqmrdWvzm8uDBrhrDs%2BwEwyMVTa4ZqnI0AS8FoMHexQV5yxbfUmihUDArft4QXrSnyCakAjaPHbknW2gyBfkmE%2FP0AHXAMx7Cg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain_tfrecords.zip'\r\n",
        "\r\n",
        "# # # # testset\r\n",
        "# # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611411985&Signature=SPlBo05ncQEsd8RLzLUOCGhZ49kM9hcob5WJ1vdJHtGtL6a663HEdtgbwO3mIuv7jGtZYQltdUDZv867XtyOGPuLThK1rKdebC3jRq5DPYnIQPK%2BJ0JX%2FLcTnGiuRgPsxevW0vfjlBsEmJzYHr%2BXsKU6TdOHMaAwyCSX1JVMtO32C3BrgPNujkQ7HiTJ2C7H5bK7mB1Gm0Li%2Bg2wV2IhFl6%2FqW0CvDf3v3eBp9yS8Xt4w18VV5hkebAlCtXts8VU%2BxIgGy8nwIoJSq2vsSUAqx%2BfsuZkOOLfL0YnQ9ziqinMQSuAv8TXcGUhmlz5NS%2Bmmu%2BeRsPbOW9YJw4nkixsow%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest.zip'\r\n",
        "\r\n",
        "# # # # test_tfrecords\r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/test_tfrecords.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611412043&Signature=qChPWagoJ3ee9%2FErHTtluS1ojjzeWYALCFY%2BZ9TlU22ED2wIe3p7N98k6RDN3re7EKft5m%2FkeHszfURu59kwAA52o7F8pkvSMXoiuRctQGue4zNza4rKmVLzyvcqbRe7KmEDqiKtT2%2BY2UPaXxc0Yk0fHqqFe%2FZSbP7mqtXFUZHoGv8vW%2BS7Y4DRMXtPNbh5tBX9vHeDNJQ2UhIDOJwzfJCNWsFX5LZBohl7%2BjtzkGee%2FWPCel%2FCbdcddj%2BAvq1CMsRx8vpxRxNnubFCxTY8daCkZm4%2Bi%2FTZl92alLXWeaWda2RcidU2X7oGLbgdYhv3fzSGbBgM18VbJTDO7L71qg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest_tfrecords.zip'\r\n",
        "\r\n",
        "# # # # train.csv\r\n",
        "# !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1612356318&Signature=lh2uk0xwhvoC1FXe2IXtIRGKI4Oj%2FW%2F1Vdir6z%2FUbcCD6HsUCsGJu0eZmiUu1EQYDxv%2B6QWeA1Z5tev2fJTAsp9fAuSkbMRQfCclKgvV5bH5lcBdGkCAQAye6gMUIb6%2BXVMtSS6gQnCNjLisommB6%2BYqVeFcnATyLRxplrNPdxoQYMnOgJQKDWPqAvH0HAoYRzJVat%2BB19DXVFyQQHXc8Hdwv537NLHwDLNuI3F%2BM40PjpuIGPxEcRqVy%2Bj0RGFG5A1%2FgeylicvBq7j0%2FJ0ixo5nix%2FK1GyY7n%2FTOdIKV8rGYNrV1zhi2oGb2SoODfJ1FrmcGu6ikcYetp5ixDlOZg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip'\r\n",
        "\r\n",
        "# # # # submission sample\r\n",
        "# # # !wget \"https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/data?select=sample_submission.csv\"\r\n",
        "\r\n",
        "# # # # train annotations \r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train_annotations.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611835498&Signature=DftuTDD7S8H3eTfh%2FLQA50BWtL%2BSATrjxebLTtDXUMN9g4XyzYqCLy6C1pzb9ilL9tS23LI5tUf69e%2B5DxhY2SZBwyQXGss8H69%2F8yewJee93tSn1Asl3z19ExCzGji0rOmritXmVNuLhzApyK6KOw86NfL5pGrXhuBo%2FYSwPDsLpdnYcLsh7m09xfgjtci%2FomGFy3j6hhZxIJyYOwol9wYRWlOFFEtxq0lQ1l8BSv6O6Z1Yl9WV%2FzIV%2FJwA1YUYtHpeAENoGutDAfOAS7ogALme3KOgDMsK4Zv3uJ9Ofkamhz1sMM8g61gdug%2BBpKZY0xmJrrsLQ4NfEL09zRUmaA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain_annotations.csv.zip'\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3f4srgdOJ53"
      },
      "source": [
        "# !mkdir /content/trainset\r\n",
        "# !mkdir /content/trainset/data/\r\n",
        "# !mkdir /content/trainset/data/1/\r\n",
        "# !unzip '/content/train.zip' -d /content/trainset/data/1/\r\n",
        "# # # # !unzip '/content/train_tfrecords.zip' -d /content/trainset/tf_records/\r\n",
        "# # # # !unzip '/content/train_annotations.csv.zip' -d /content/trainset/\r\n",
        "# !unzip '/content/train.csv.zip' -d /content/trainset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvDL9xh2Qc6N"
      },
      "source": [
        "# !mkdir /content/testset\r\n",
        "# !unzip '/content/test.zip' -d /content/testset/data\r\n",
        "# !unzip '/content/test_tfrecords.zip' -d /content/testset/test_tfrecords/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-LgJKyRBziW"
      },
      "source": [
        "# !rm /content/test.zip\r\n",
        "# !rm /content/test_tfrecords.zip\r\n",
        "# !rm /content/train.csv.zip\r\n",
        "# !rm /content/train.zip\r\n",
        "# !rm /content/train_annotations.csv.zip\r\n",
        "# !rm /content/train_tfrecords.zip\r\n",
        "# !rm -rf /content/trainset/data/1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPQAQU7ncDsr"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "# sample_submission = pd.read_csv('/content/sample_submission.csv')\r\n",
        "# sample_submission.head()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikRE9MDNnQGK"
      },
      "source": [
        "train_csv = pd.read_csv('/content/trainset/train.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgM8GN2e1izJ"
      },
      "source": [
        "def sampling(trainset, sample_per_class):\r\n",
        "  \r\n",
        "\r\n",
        "    index_list = []\r\n",
        "    validation_index_list = []\r\n",
        "    threshold = np.full((12, ), sample_per_class)\r\n",
        "    for index, row in train_csv.iterrows():\r\n",
        "        sample = row[1:-1].values\r\n",
        "        flag = True\r\n",
        "        for i in range(11):\r\n",
        "            if threshold[i] > 0 :\r\n",
        "              if sample[i] == 1:\r\n",
        "                flag = False\r\n",
        "                threshold[i] -= 1\r\n",
        "                index_list.append(index)\r\n",
        "                break\r\n",
        "                \r\n",
        "              else:\r\n",
        "                pass  \r\n",
        "            else:\r\n",
        "              pass\r\n",
        "        if flag:\r\n",
        "          if threshold[11] > 0:\r\n",
        "            threshold[11] -= 1  \r\n",
        "            index_list.append(index) \r\n",
        "        else:\r\n",
        "            validation_index_list.append(index)\r\n",
        "\r\n",
        "\r\n",
        "    return index_list, validation_index_list\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLVFb6FLPtEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dff0403-7a90-4484-f2a2-60efdef3e27f"
      },
      "source": [
        "len(train_csv)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UdhB_tN9XpN",
        "outputId": "39f8c143-d2da-40fe-e056-7eafafc5c769"
      },
      "source": [
        "sampled_index, validation_index = sampling(train_csv, 700)\r\n",
        "validation_names =train_csv.iloc[validation_index, :]\r\n",
        "print(len(validation_names))\r\n",
        "images_name =train_csv.iloc[sampled_index, :]\r\n",
        "len(images_name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6910"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLHK1Y7rwgby"
      },
      "source": [
        "from __future__ import print_function, division\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import torchvision\r\n",
        "from skimage import io, transform\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUnroASw1rgR"
      },
      "source": [
        "# we calculate dataset mean and standard derivation only once \r\n",
        "\r\n",
        "\r\n",
        "# from tqdm import tqdm \r\n",
        "\r\n",
        "# dataset = datasets.ImageFolder('/content/trainset/data', transform=transforms.Compose([transforms.Resize((512, 512)),\r\n",
        "#                                                                                        transforms.ToTensor()]))\r\n",
        "\r\n",
        "# loader = torch.utils.data.DataLoader(dataset,\r\n",
        "#                          batch_size=10,\r\n",
        "#                          num_workers=0,\r\n",
        "#                          shuffle=False)\r\n",
        "\r\n",
        "# var = 0.0\r\n",
        "# mean = 0.0\r\n",
        "# for i, data in tqdm(enumerate(loader)):\r\n",
        "#     images = data[0]\r\n",
        "#     batch_samples = images.size(0) \r\n",
        "#     images = images.view(batch_samples, images.size(1), -1)\r\n",
        "#     mean += images.mean(2).sum(0)\r\n",
        "#     var += ((images - mean.unsqueeze(1))**2).sum([0,2])\r\n",
        "# std = torch.sqrt(var / (len(loader.dataset)*224*224))\r\n",
        "# mean = mean / len(loader.dataset)\r\n",
        "\r\n",
        "# print('dataset mean: ', mean)\r\n",
        "# print('dataset std: ', std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaxSOFwmBeWS"
      },
      "source": [
        "# these results are calculated using above cell \r\n",
        "\r\n",
        "mean = np.array([0.4823, 0.4823, 0.4823])\r\n",
        "std = np.array([0.191473164, 0.191473164, 0.191473164])\r\n",
        "\r\n",
        "\r\n",
        "# mean = np.array([0.4823])\r\n",
        "# std = np.array([19147.3164])\r\n",
        "# mean = np.array([0.4823])\r\n",
        "# std = np.array([0.5])\r\n",
        "# mean = np.array([0.5057, 0.5057, 0.5057])\r\n",
        "# std = np.array([0.1902, 0.1902, 0.1902])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD6dPyTlt_lR"
      },
      "source": [
        "from PIL import Image\r\n",
        "\r\n",
        "\r\n",
        "class RANZCRDataset(Dataset):\r\n",
        "\r\n",
        "\r\n",
        "    def __init__(self, csv_file='/content/trainset/train.csv', root_dir='/content/trainset/data/1', transform=transform, images_name=None):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            csv_file (string): Path to the csv file with annotations.\r\n",
        "            root_dir (string): Directory with all the images.\r\n",
        "            transform (callable, optional): Optional transform to be applied\r\n",
        "                on a sample.\r\n",
        "        \"\"\"\r\n",
        "        self.Images_name = images_name\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.transform = transform\r\n",
        "        \r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.Images_name)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if torch.is_tensor(idx):\r\n",
        "            idx = idx.tolist()\r\n",
        "\r\n",
        "        img_name = os.path.join(self.root_dir,\r\n",
        "                                self.Images_name.iloc[idx, 0])\r\n",
        "        image = Image.open(img_name + '.jpg').convert('RGB')\r\n",
        "        labels = self.Images_name.iloc[idx, 1:-1].values\r\n",
        "        labels = labels.astype(np.int)\r\n",
        "        labels = torch.from_numpy(labels)\r\n",
        "        sample = {'image': image, 'label': labels }\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "\r\n",
        "          sample['image'] = self.transform(sample['image'])\r\n",
        "\r\n",
        "\r\n",
        "        return sample"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgSZrpo8RAxk"
      },
      "source": [
        "import torch\r\n",
        "from torchvision import datasets, transforms\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "def load_data(csv_file='/content/trainset/train.csv', data_dir='/content/trainset/data/1'):\r\n",
        "\r\n",
        "  transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "                                  transforms.Resize((1024, 1024)),\r\n",
        "                                  transforms.CenterCrop(904),\r\n",
        "                                  transforms.Normalize(mean, std)])\r\n",
        "\r\n",
        "\r\n",
        "  trainset = RANZCRDataset(csv_file=csv_file,\r\n",
        "                                      root_dir=data_dir, transform=transform, images_name=images_name)\r\n",
        "\r\n",
        "\r\n",
        "  validation = RANZCRDataset(csv_file=csv_file,\r\n",
        "                                    root_dir=data_dir, transform=transform, images_name=validation_names)\r\n",
        "  \r\n",
        "\r\n",
        "  \r\n",
        "  return trainset, validation\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Tocrklk9gY"
      },
      "source": [
        "# train_data_loader = torch.utils.data.DataLoader(trainset,\r\n",
        "#                                           batch_size=8,\r\n",
        "#                                           shuffle=True,\r\n",
        "#                                           num_workers=0)\r\n",
        "\r\n",
        "\r\n",
        "# validation_data_loader = torch.utils.data.DataLoader(validation,\r\n",
        "#                                           batch_size=8,\r\n",
        "#                                           shuffle=True,\r\n",
        "#                                           num_workers=0)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8muYGHBGwZen"
      },
      "source": [
        "# def imshow(img):\r\n",
        "#     npimg = img.numpy()\r\n",
        "#     npimg = ((npimg * std[0]) + mean[0]) # unnormalize\r\n",
        "#     plt.imshow((np.transpose(npimg, (1, 2, 0)) * 255).astype(np.uint8))\r\n",
        "#     plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# # get some random training images\r\n",
        "# dataiter = iter(train_data_loader)\r\n",
        "# sample = dataiter.next()\r\n",
        "# print(sample['image'].shape)\r\n",
        "# imshow(torchvision.utils.make_grid(sample['image']))\r\n",
        "# print(sample['label'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dpyq8uYr8-7"
      },
      "source": [
        "model = torchvision.models.resnet152(pretrained=False, progress=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oFre0HvsMRj"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpItSJloHImE"
      },
      "source": [
        "for param in model.parameters():\r\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLymbGLgMpu_"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F \r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self, l1=512, l2=256, c1=3):\r\n",
        "    super(Net, self).__init__()\r\n",
        "    self.model = model\r\n",
        "    self.conv1 = nn.Conv2d(3, c1, 5)\r\n",
        "    self.conv2 = nn.Conv2d(c1, 3, 1)\r\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\r\n",
        "    self.sigmoid = nn.Sigmoid()\r\n",
        "    self.fc1 = nn.Linear(1000, l1)\r\n",
        "    self.fc2 = nn.Linear(l1, l2)\r\n",
        "    self.fc_final = nn.Linear(l2, 11)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    x = self.pool2(F.relu(self.conv1(x)))\r\n",
        "    x = self.pool2(F.relu(self.conv2(x)))\r\n",
        "    x = self.model(x)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = F.relu(self.fc2(x))\r\n",
        "    x = self.sigmoid(self.fc_final(x))\r\n",
        "    return x\r\n",
        "\r\n",
        "# Network = Net()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_7y4DPkHgjH"
      },
      "source": [
        "# def count_parameters(model):\r\n",
        "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "# print(count_parameters(model))\r\n",
        "# print(count_parameters(Network))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Wb3uf0gF3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c896167b-690b-4cb9-aacc-28c766f96e06"
      },
      "source": [
        "\r\n",
        "# Network.load_state_dict(torch.load('/content/drive/MyDrive/model.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DrXdrMNoE6s"
      },
      "source": [
        "####################################\r\n",
        "# !pip install ray\r\n",
        "# !pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2jjjLlPnfOl"
      },
      "source": [
        "\r\n",
        "from functools import partial\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import random_split\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from ray import tune\r\n",
        "from ray.tune import CLIReporter\r\n",
        "from ray.tune.schedulers import ASHAScheduler\r\n",
        "import tensorboardX"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSY9uhoeWodl"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "def roc_auc_compute_fn(y_preds, y_targets):\r\n",
        "\r\n",
        "    \r\n",
        "    try:\r\n",
        "        from sklearn.metrics import roc_auc_score\r\n",
        "    except ImportError:\r\n",
        "        raise RuntimeError(\"This contrib module requires sklearn to be installed.\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    y_true = y_targets.cpu().detach().numpy()\r\n",
        "    y_pred = y_preds.cpu().detach().numpy()\r\n",
        "    try:\r\n",
        "      return roc_auc_score(y_pred, y_true, average='micro')\r\n",
        "    except ValueError:\r\n",
        "      return None\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN88p-B3m3PU"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "def train_ranzcr(config, checkpoint_dir=None, data_dir=None):\r\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\r\n",
        "\r\n",
        "    device = \"cpu\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = \"cuda:0\"\r\n",
        "        if torch.cuda.device_count() > 1:\r\n",
        "            net = nn.DataParallel(net)\r\n",
        "    net.to(device)\r\n",
        "\r\n",
        "    criterion = nn.BCELoss()\r\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=config[\"wd\"])\r\n",
        "\r\n",
        "    if checkpoint_dir:\r\n",
        "        model_state, optimizer_state = torch.load(\r\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\r\n",
        "        net.load_state_dict(model_state)\r\n",
        "        optimizer.load_state_dict(optimizer_state)\r\n",
        "\r\n",
        "    trainset, testset = load_data(data_dir)\r\n",
        "\r\n",
        "    test_abs = int(len(trainset) * 0.8)\r\n",
        "    train_subset, val_subset = random_split(\r\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\r\n",
        "\r\n",
        "    trainloader = torch.utils.data.DataLoader(\r\n",
        "        train_subset,\r\n",
        "        batch_size=int(config[\"batch_size\"]),\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=8)\r\n",
        "    valloader = torch.utils.data.DataLoader(\r\n",
        "        val_subset,\r\n",
        "        batch_size=int(config[\"batch_size\"]),\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=8)\r\n",
        "\r\n",
        "    for epoch in range(10):  # loop over the dataset multiple times\r\n",
        "        running_loss = 0.0\r\n",
        "        epoch_steps = 0\r\n",
        "        for i, data in enumerate(trainloader, 0):\r\n",
        "            # get the inputs; data is a list of [inputs, labels]\r\n",
        "            inputs, labels = data['image'].float(), data['label'].float()\r\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "            # zero the parameter gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # forward + backward + optimize\r\n",
        "            outputs = net(inputs)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            # print statistics\r\n",
        "            running_loss += loss.item()\r\n",
        "            epoch_steps += 1\r\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\r\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\r\n",
        "                                                running_loss / epoch_steps))\r\n",
        "                running_loss = 0.0\r\n",
        "\r\n",
        "        # Validation loss\r\n",
        "        val_loss = 0.0\r\n",
        "        val_steps = 0\r\n",
        "        total = 0\r\n",
        "        correct = 0\r\n",
        "        accuracy = 0\r\n",
        "        batch_counter = 0\r\n",
        "        for i, data in enumerate(valloader, 0):\r\n",
        "            with torch.no_grad():\r\n",
        "                inputs, labels = data['image'].float(), data['label'].float()\r\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "                outputs = net(inputs)\r\n",
        "                # _, predicted = torch.max(outputs.data, 1)\r\n",
        "                # total += labels.size(0)\r\n",
        "                # correct += (predicted == labels).sum().item()\r\n",
        "                # my_validation_outputs = (outputs > 0.5)\r\n",
        "                # print('------------------------------------------------------------------------------')\r\n",
        "                # print(labels)\r\n",
        "                # print(my_validation_outputs)\r\n",
        "                # print('------------------------------------------------------------------------------')\r\n",
        "                # accuracy += auc_s(labels, my_validation_outputs)\r\n",
        "                # batch_counter += 1\r\n",
        "                accuracy += roc_auc_compute_fn(labels, outputs)\r\n",
        "                batch_counter += 1\r\n",
        "\r\n",
        "                loss = criterion(outputs, labels)\r\n",
        "                val_loss += loss.cpu().numpy()\r\n",
        "                val_steps += 1\r\n",
        "\r\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\r\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\r\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\r\n",
        "\r\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=(accuracy / batch_counter))\r\n",
        "    torch.save((net.state_dict(), optimizer.state_dict()), '/content/drive/MyDrive/RANZCR/model_%.3f.pth'%(accuracy / batch_counter))\r\n",
        "    print(\"Finished Training\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCprU3xDng_X"
      },
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\r\n",
        "    trainset, testset = load_data()\r\n",
        "\r\n",
        "    testloader = torch.utils.data.DataLoader(\r\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2)\r\n",
        "\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    batch_counter_test = 0\r\n",
        "    accuracy_test = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in testloader:\r\n",
        "            images, labels = data['image'].float(), data['label'].float()\r\n",
        "            images, labels = images.to(device), labels.to(device)\r\n",
        "            outputs = net(images)\r\n",
        "            # _, predicted = torch.max(outputs.data, 1)\r\n",
        "            # total += labels.size(0)\r\n",
        "            # correct += (predicted == labels).sum().item()\r\n",
        "            # my_test_outputs = (outputs > 0.5)\r\n",
        "            # accuracy_test += accuracy_score(labels, my_test_outputs)\r\n",
        "            # batch_counter_test += 1\r\n",
        "            accuracy_test += roc_auc_compute_fn(labels, outputs)\r\n",
        "            batch_counter_test += 1\r\n",
        "\r\n",
        "\r\n",
        "    return accuracy_test / batch_counter_test"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4x9x0Gvnl1M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fdcc7ea-f412-4599-ce81-986eeabb0b19"
      },
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\r\n",
        "    data_dir = os.path.abspath(\"/content/trainset/data\")\r\n",
        "    load_data(data_dir)\r\n",
        "    config = {\r\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(5, 9)),\r\n",
        "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(4, 9)),\r\n",
        "        \"lr\": tune.loguniform(1e-5, 1e-1),\r\n",
        "        \"wd\": tune.loguniform(1e-6, 1e-2),\r\n",
        "        \"c1\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 6)),\r\n",
        "        \"batch_size\": tune.choice([4, 8, 16])\r\n",
        "    }\r\n",
        "    scheduler = ASHAScheduler(\r\n",
        "        metric=\"loss\",\r\n",
        "        mode=\"min\",\r\n",
        "        max_t=max_num_epochs,\r\n",
        "        grace_period=1,\r\n",
        "        reduction_factor=2)\r\n",
        "    reporter = CLIReporter(\r\n",
        "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\r\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\r\n",
        "    result = tune.run(\r\n",
        "        partial(train_ranzcr, data_dir=data_dir),\r\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\r\n",
        "        config=config,\r\n",
        "        num_samples=num_samples,\r\n",
        "        scheduler=scheduler,\r\n",
        "        progress_reporter=reporter)\r\n",
        "\r\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\r\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\r\n",
        "    print(\"Best trial final validation loss: {}\".format(\r\n",
        "        best_trial.last_result[\"loss\"]))\r\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\r\n",
        "        best_trial.last_result[\"accuracy\"]))\r\n",
        "\r\n",
        "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\r\n",
        "    device = \"cpu\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = \"cuda:0\"\r\n",
        "        if gpus_per_trial > 1:\r\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\r\n",
        "    best_trained_model.to(device)\r\n",
        "\r\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\r\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\r\n",
        "        best_checkpoint_dir, \"checkpoint\"))\r\n",
        "    best_trained_model.load_state_dict(model_state)\r\n",
        "\r\n",
        "    test_acc = test_accuracy(best_trained_model, device)\r\n",
        "    torch.save(best_trained_model.state_dict(), '/content/drive/MyDrive/model_second_train.pth')\r\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # You can change the number of GPUs per trial here:\r\n",
        "    main(num_samples=20, max_num_epochs=10, gpus_per_trial=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 18:41:32,340\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "2021-01-31 18:41:35,360\tWARNING experiment.py:285 -- No name detected on trainable. Using DEFAULT.\n",
            "2021-01-31 18:41:35,361\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n",
            "2021-01-31 18:41:45,407\tWARNING worker.py:1034 -- Warning: The actor ImplicitFunc has size 243588516 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_18-41-36\n",
            "Number of trials: 1/20 (1 RUNNING)\n",
            "+---------------------+----------+-------+--------------+------+------+------+------------+-------------+\n",
            "| Trial name          | status   | loc   |   batch_size |   c1 |   l1 |   l2 |         lr |          wd |\n",
            "|---------------------+----------+-------+--------------+------+------+------+------------+-------------|\n",
            "| DEFAULT_f3c4f_00000 | RUNNING  |       |            8 |    8 |   32 |   64 | 0.00157554 | 8.44432e-06 |\n",
            "+---------------------+----------+-------+--------------+------+------+------+------------+-------------+\n",
            "\n",
            "\n",
            "Result for DEFAULT_f3c4f_00000:\n",
            "  accuracy: 0.7926947207226062\n",
            "  date: 2021-01-31_18-54-13\n",
            "  done: false\n",
            "  experiment_id: 37b1e9f351de4cf2b15d4d8616829652\n",
            "  hostname: 1ac868f5ca37\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.4134499549521187\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 738\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 744.3668553829193\n",
            "  time_this_iter_s: 744.3668553829193\n",
            "  time_total_s: 744.3668553829193\n",
            "  timestamp: 1612119253\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: f3c4f_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.6/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.4134499549521187\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_18-41-36\n",
            "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+---------+------------+----------------------+\n",
            "| Trial name          | status   | loc            |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |    loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+---------+------------+----------------------|\n",
            "| DEFAULT_f3c4f_00000 | RUNNING  | 172.28.0.2:738 |            8 |    8 |   32 |   64 | 0.00157554  | 8.44432e-06 | 0.41345 |   0.792695 |                    1 |\n",
            "| DEFAULT_f3c4f_00001 | PENDING  |                |            4 |   16 |  256 |   64 | 0.000643671 | 0.000588386 |         |            |                      |\n",
            "+---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 18:54:15,318\tWARNING util.py:142 -- The `process_trial_save` operation took 1.779 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_f3c4f_00000:\n",
            "  accuracy: 0.7940359821694034\n",
            "  date: 2021-01-31_19-06-28\n",
            "  done: false\n",
            "  experiment_id: 37b1e9f351de4cf2b15d4d8616829652\n",
            "  hostname: 1ac868f5ca37\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.41082536157845073\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 738\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1479.5708742141724\n",
            "  time_this_iter_s: 735.204018831253\n",
            "  time_total_s: 1479.5708742141724\n",
            "  timestamp: 1612119988\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: f3c4f_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 6.8/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.41082536157845073 | Iter 1.000: -0.4134499549521187\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_18-41-36\n",
            "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------+\n",
            "| Trial name          | status   | loc            |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |     loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------|\n",
            "| DEFAULT_f3c4f_00000 | RUNNING  | 172.28.0.2:738 |            8 |    8 |   32 |   64 | 0.00157554  | 8.44432e-06 | 0.410825 |   0.794036 |                    2 |\n",
            "| DEFAULT_f3c4f_00001 | PENDING  |                |            4 |   16 |  256 |   64 | 0.000643671 | 0.000588386 |          |            |                      |\n",
            "+---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 19:06:30,571\tWARNING util.py:142 -- The `process_trial_save` operation took 1.790 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_f3c4f_00000:\n",
            "  accuracy: 0.7990896255885835\n",
            "  date: 2021-01-31_19-18-48\n",
            "  done: false\n",
            "  experiment_id: 37b1e9f351de4cf2b15d4d8616829652\n",
            "  hostname: 1ac868f5ca37\n",
            "  iterations_since_restore: 3\n",
            "  loss: 0.40863572362530437\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 738\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2219.265294313431\n",
            "  time_this_iter_s: 739.6944200992584\n",
            "  time_total_s: 2219.265294313431\n",
            "  timestamp: 1612120728\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: f3c4f_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 7.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.41082536157845073 | Iter 1.000: -0.4134499549521187\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_18-41-36\n",
            "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------+\n",
            "| Trial name          | status   | loc            |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |     loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------|\n",
            "| DEFAULT_f3c4f_00000 | RUNNING  | 172.28.0.2:738 |            8 |    8 |   32 |   64 | 0.00157554  | 8.44432e-06 | 0.408636 |    0.79909 |                    3 |\n",
            "| DEFAULT_f3c4f_00001 | PENDING  |                |            4 |   16 |  256 |   64 | 0.000643671 | 0.000588386 |          |            |                      |\n",
            "+---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 19:18:50,222\tWARNING util.py:142 -- The `process_trial_save` operation took 1.836 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for DEFAULT_f3c4f_00000:\n",
            "  accuracy: 0.7989148023665195\n",
            "  date: 2021-01-31_19-31-05\n",
            "  done: false\n",
            "  experiment_id: 37b1e9f351de4cf2b15d4d8616829652\n",
            "  hostname: 1ac868f5ca37\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.4094514280040829\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 738\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2956.422619819641\n",
            "  time_this_iter_s: 737.1573255062103\n",
            "  time_total_s: 2956.422619819641\n",
            "  timestamp: 1612121465\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: f3c4f_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 7.3/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.4094514280040829 | Iter 2.000: -0.41082536157845073 | Iter 1.000: -0.4134499549521187\n",
            "Resources requested: 2/2 CPUs, 1/1 GPUs, 0.0/7.47 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_18-41-36\n",
            "Number of trials: 2/20 (1 PENDING, 1 RUNNING)\n",
            "+---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------+\n",
            "| Trial name          | status   | loc            |   batch_size |   c1 |   l1 |   l2 |          lr |          wd |     loss |   accuracy |   training_iteration |\n",
            "|---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------|\n",
            "| DEFAULT_f3c4f_00000 | RUNNING  | 172.28.0.2:738 |            8 |    8 |   32 |   64 | 0.00157554  | 8.44432e-06 | 0.409451 |   0.798915 |                    4 |\n",
            "| DEFAULT_f3c4f_00001 | PENDING  |                |            4 |   16 |  256 |   64 | 0.000643671 | 0.000588386 |          |            |                      |\n",
            "+---------------------+----------+----------------+--------------+------+------+------+-------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 19:31:07,372\tWARNING util.py:142 -- The `process_trial_save` operation took 1.828 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b7ecc1ba5411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# You can change the number of GPUs per trial here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-b7ecc1ba5411>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         progress_reporter=reporter)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mtune_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m                     trial=next_trial)\n\u001b[1;32m    359\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m         )\n\u001b[1;32m   1515\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjwmUvBRYqR6"
      },
      "source": [
        "# for epoch in range(20):\r\n",
        "\r\n",
        "#   running_loss = 0.0\r\n",
        "#   best_validation_auc_score = 0\r\n",
        "\r\n",
        "#   for i, data in enumerate(train_data_loader, 0):\r\n",
        "    \r\n",
        "\r\n",
        "#     inputs = data['image'].float()\r\n",
        "#     label = data['label'].float()\r\n",
        "#     optimizer.zero_grad()\r\n",
        "#     outputs = Network(inputs)\r\n",
        "#     loss = loss_function(outputs, label)\r\n",
        "#     loss.backward()\r\n",
        "#     optimizer.step()\r\n",
        "\r\n",
        "#     auc_score = roc_auc_compute_fn(outputs, label)\r\n",
        "#     running_loss += loss.item()\r\n",
        "#     if (i % 10 == 0) and (i > 9):\r\n",
        "#       print('[epoch: %d, batch: %5d] training loss: %.3f training auc score: %.3f' %( epoch + 1, i, (running_loss/10), auc_score))\r\n",
        "      \r\n",
        "#       dataiter = iter(validation_data_loader)\r\n",
        "#       sample = dataiter.next()\r\n",
        "#       validation_inputs = sample['image'].float()\r\n",
        "#       validation_label = sample['label'].float()\r\n",
        "#       validation_outputs = Network(validation_inputs)\r\n",
        "#       validation_loss = loss_function(validation_outputs, validation_label)\r\n",
        "#       validation_auc_score = roc_auc_compute_fn(validation_outputs, validation_label)\r\n",
        "\r\n",
        "#       print('[epoch: %d, batch: %5d] <validation 10 random sample> loss: %.3f , auc score: %.3f' %( epoch + 1, i, validation_loss, validation_auc_score))\r\n",
        "\r\n",
        "\r\n",
        "#       running_loss = 0.0\r\n",
        "\r\n",
        "#   try:\r\n",
        "#     if validation_auc_score > best_validation_auc_score:\r\n",
        "#       torch.save(Network.state_dict(), '/content/drive/MyDrive/model_second_train.pth')\r\n",
        "#       best_validation_auc_score = validation_auc_score\r\n",
        "#   except ValueError:\r\n",
        "#     pass\r\n",
        "  \r\n",
        "    \r\n",
        "# print('Finished Training Network')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQkE8mE4ssFm"
      },
      "source": [
        "# # Quick evaluation \r\n",
        "\r\n",
        "# # get some random training images\r\n",
        "# dataiter = iter(train_data_loader)\r\n",
        "# sample = dataiter.next()\r\n",
        "# inputs = sample['image'].float()\r\n",
        "# label = sample['label'].float()\r\n",
        "# print(inputs.shape)\r\n",
        "# batch_predicted_values = Network(inputs)\r\n",
        "# imshow(torchvision.utils.make_grid(sample['image']))\r\n",
        "# print(sample['label'])\r\n",
        "# print(batch_predicted_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnhhfYNZJbhc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}