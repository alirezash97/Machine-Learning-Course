{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RANZCR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezash97/Machine-Learning-Course/blob/main/Final_Project/RANZCR_fine_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTBBnTu6fgXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360be255-517a-4f87-8c4f-6553aa6240a3"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CiPXKgnKjBy"
      },
      "source": [
        "# # # # trainset\r\n",
        "# !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1612356291&Signature=Y0prr2JieE4gY4AM9EwN3MiMCxiaLjN2t5v6pD%2Fn08VSNiJWS2iNK%2FQAaQOeRAnH578jfJmQA8hdCRgLL6yz2NUuXRz3Vey0DlcexHiEQLn5eqUeDlFx9Z76zxf6KNd%2BLxxwofJzbJrwI2OMoC2tb26jlASakwqFUaX14f5U9pJ2Ct9Nw6%2Bf515mtCUtmX1qroNRLXjWuUvFRT%2FmZQKj54raaqr2%2BhTYSYYEB8tuEDAi11p9U6tniCKX%2B%2BEbV%2B4RLCGZQRjtlt5%2FfadwcVLbSpcBp%2BrNaMZEOz2A8jwJNpmWXHemo%2FARNnobvn7WIKvSVHDrZ%2FZ61gbEWVaOk0xz5w%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.zip'\r\n",
        "\r\n",
        "# # # train_tfrecords\r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train_tfrecords.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611835011&Signature=OBxBwfMr9c0gB7Qmiiv9lGIHSqsT2ocsodWh1H56xb%2FYMBjLkiPKxiDXMBPnvOnaUGhMmKTmlpK06O8721DFO1hCNrq9757gZrxaVpm4400ABhzZ86NgLyLfC7Zse6GUlByeDrdd2Dk6KwI%2BjHFPg4TFFov3DW13I2%2FKw9h22tNbssdkfTA7OZgll1EW9Ynh6g%2F2ULQrmTtjkfdLbObPyniLEA5vHLXnK0ySw%2FaNS%2BCICHgGf4ECYqmrdWvzm8uDBrhrDs%2BwEwyMVTa4ZqnI0AS8FoMHexQV5yxbfUmihUDArft4QXrSnyCakAjaPHbknW2gyBfkmE%2FP0AHXAMx7Cg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain_tfrecords.zip'\r\n",
        "\r\n",
        "# # # # testset\r\n",
        "# # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611411985&Signature=SPlBo05ncQEsd8RLzLUOCGhZ49kM9hcob5WJ1vdJHtGtL6a663HEdtgbwO3mIuv7jGtZYQltdUDZv867XtyOGPuLThK1rKdebC3jRq5DPYnIQPK%2BJ0JX%2FLcTnGiuRgPsxevW0vfjlBsEmJzYHr%2BXsKU6TdOHMaAwyCSX1JVMtO32C3BrgPNujkQ7HiTJ2C7H5bK7mB1Gm0Li%2Bg2wV2IhFl6%2FqW0CvDf3v3eBp9yS8Xt4w18VV5hkebAlCtXts8VU%2BxIgGy8nwIoJSq2vsSUAqx%2BfsuZkOOLfL0YnQ9ziqinMQSuAv8TXcGUhmlz5NS%2Bmmu%2BeRsPbOW9YJw4nkixsow%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest.zip'\r\n",
        "\r\n",
        "# # # # test_tfrecords\r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/test_tfrecords.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611412043&Signature=qChPWagoJ3ee9%2FErHTtluS1ojjzeWYALCFY%2BZ9TlU22ED2wIe3p7N98k6RDN3re7EKft5m%2FkeHszfURu59kwAA52o7F8pkvSMXoiuRctQGue4zNza4rKmVLzyvcqbRe7KmEDqiKtT2%2BY2UPaXxc0Yk0fHqqFe%2FZSbP7mqtXFUZHoGv8vW%2BS7Y4DRMXtPNbh5tBX9vHeDNJQ2UhIDOJwzfJCNWsFX5LZBohl7%2BjtzkGee%2FWPCel%2FCbdcddj%2BAvq1CMsRx8vpxRxNnubFCxTY8daCkZm4%2Bi%2FTZl92alLXWeaWda2RcidU2X7oGLbgdYhv3fzSGbBgM18VbJTDO7L71qg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest_tfrecords.zip'\r\n",
        "\r\n",
        "# # # # train.csv\r\n",
        "# !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1612356318&Signature=lh2uk0xwhvoC1FXe2IXtIRGKI4Oj%2FW%2F1Vdir6z%2FUbcCD6HsUCsGJu0eZmiUu1EQYDxv%2B6QWeA1Z5tev2fJTAsp9fAuSkbMRQfCclKgvV5bH5lcBdGkCAQAye6gMUIb6%2BXVMtSS6gQnCNjLisommB6%2BYqVeFcnATyLRxplrNPdxoQYMnOgJQKDWPqAvH0HAoYRzJVat%2BB19DXVFyQQHXc8Hdwv537NLHwDLNuI3F%2BM40PjpuIGPxEcRqVy%2Bj0RGFG5A1%2FgeylicvBq7j0%2FJ0ixo5nix%2FK1GyY7n%2FTOdIKV8rGYNrV1zhi2oGb2SoODfJ1FrmcGu6ikcYetp5ixDlOZg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip'\r\n",
        "\r\n",
        "# # # # submission sample\r\n",
        "# # # !wget \"https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/data?select=sample_submission.csv\"\r\n",
        "\r\n",
        "# # # # train annotations \r\n",
        "# # # !wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23870/1781260/compressed/train_annotations.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1611835498&Signature=DftuTDD7S8H3eTfh%2FLQA50BWtL%2BSATrjxebLTtDXUMN9g4XyzYqCLy6C1pzb9ilL9tS23LI5tUf69e%2B5DxhY2SZBwyQXGss8H69%2F8yewJee93tSn1Asl3z19ExCzGji0rOmritXmVNuLhzApyK6KOw86NfL5pGrXhuBo%2FYSwPDsLpdnYcLsh7m09xfgjtci%2FomGFy3j6hhZxIJyYOwol9wYRWlOFFEtxq0lQ1l8BSv6O6Z1Yl9WV%2FzIV%2FJwA1YUYtHpeAENoGutDAfOAS7ogALme3KOgDMsK4Zv3uJ9Ofkamhz1sMM8g61gdug%2BBpKZY0xmJrrsLQ4NfEL09zRUmaA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain_annotations.csv.zip'\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3f4srgdOJ53"
      },
      "source": [
        "# !mkdir /content/trainset\r\n",
        "# !mkdir /content/trainset/data/\r\n",
        "# !mkdir /content/trainset/data/1/\r\n",
        "# !unzip '/content/train.zip' -d /content/trainset/data/1/\r\n",
        "# # # # !unzip '/content/train_tfrecords.zip' -d /content/trainset/tf_records/\r\n",
        "# # # # !unzip '/content/train_annotations.csv.zip' -d /content/trainset/\r\n",
        "# !unzip '/content/train.csv.zip' -d /content/trainset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvDL9xh2Qc6N"
      },
      "source": [
        "# !mkdir /content/testset\r\n",
        "# !unzip '/content/test.zip' -d /content/testset/data\r\n",
        "# !unzip '/content/test_tfrecords.zip' -d /content/testset/test_tfrecords/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-LgJKyRBziW"
      },
      "source": [
        "# !rm /content/test.zip\r\n",
        "# !rm /content/test_tfrecords.zip\r\n",
        "# !rm /content/train.csv.zip\r\n",
        "# !rm /content/train.zip\r\n",
        "# !rm /content/train_annotations.csv.zip\r\n",
        "# !rm /content/train_tfrecords.zip\r\n",
        "# !rm -rf /content/trainset/data/1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPQAQU7ncDsr"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "# sample_submission = pd.read_csv('/content/sample_submission.csv')\r\n",
        "# sample_submission.head()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikRE9MDNnQGK"
      },
      "source": [
        "train_csv = pd.read_csv('/content/trainset/train.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgM8GN2e1izJ"
      },
      "source": [
        "def sampling(trainset, sample_per_class):\r\n",
        "  \r\n",
        "\r\n",
        "    index_list = []\r\n",
        "    validation_index_list = []\r\n",
        "    threshold = np.full((12, ), sample_per_class)\r\n",
        "    for index, row in train_csv.iterrows():\r\n",
        "        sample = row[1:-1].values\r\n",
        "        flag = True\r\n",
        "        for i in range(11):\r\n",
        "            if threshold[i] > 0 :\r\n",
        "              if sample[i] == 1:\r\n",
        "                flag = False\r\n",
        "                threshold[i] -= 1\r\n",
        "                index_list.append(index)\r\n",
        "                break\r\n",
        "                \r\n",
        "              else:\r\n",
        "                pass  \r\n",
        "            else:\r\n",
        "              pass\r\n",
        "        if flag:\r\n",
        "          if threshold[11] > 0:\r\n",
        "            threshold[11] -= 1  \r\n",
        "            index_list.append(index) \r\n",
        "        else:\r\n",
        "            validation_index_list.append(index)\r\n",
        "\r\n",
        "\r\n",
        "    return index_list, validation_index_list\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLVFb6FLPtEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116acd72-e6ac-4332-9d79-3878980b1379"
      },
      "source": [
        "len(train_csv)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UdhB_tN9XpN",
        "outputId": "d32db6b5-75ca-48fc-d01d-55d3d7f21497"
      },
      "source": [
        "sampled_index, validation_index = sampling(train_csv, 10)\r\n",
        "validation_names =train_csv.iloc[validation_index, :]\r\n",
        "print(len(validation_names))\r\n",
        "images_name =train_csv.iloc[sampled_index, :]\r\n",
        "len(images_name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLHK1Y7rwgby"
      },
      "source": [
        "from __future__ import print_function, division\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import torchvision\r\n",
        "from skimage import io, transform\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUnroASw1rgR"
      },
      "source": [
        "# we calculate dataset mean and standard derivation only once \r\n",
        "\r\n",
        "\r\n",
        "# from tqdm import tqdm \r\n",
        "\r\n",
        "# dataset = datasets.ImageFolder('/content/trainset/data', transform=transforms.Compose([transforms.Resize((512, 512)),\r\n",
        "#                                                                                        transforms.ToTensor()]))\r\n",
        "\r\n",
        "# loader = torch.utils.data.DataLoader(dataset,\r\n",
        "#                          batch_size=10,\r\n",
        "#                          num_workers=0,\r\n",
        "#                          shuffle=False)\r\n",
        "\r\n",
        "# var = 0.0\r\n",
        "# mean = 0.0\r\n",
        "# for i, data in tqdm(enumerate(loader)):\r\n",
        "#     images = data[0]\r\n",
        "#     batch_samples = images.size(0) \r\n",
        "#     images = images.view(batch_samples, images.size(1), -1)\r\n",
        "#     mean += images.mean(2).sum(0)\r\n",
        "#     var += ((images - mean.unsqueeze(1))**2).sum([0,2])\r\n",
        "# std = torch.sqrt(var / (len(loader.dataset)*224*224))\r\n",
        "# mean = mean / len(loader.dataset)\r\n",
        "\r\n",
        "# print('dataset mean: ', mean)\r\n",
        "# print('dataset std: ', std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaxSOFwmBeWS"
      },
      "source": [
        "# these results are calculated using above cell \r\n",
        "\r\n",
        "mean = np.array([0.4823, 0.4823, 0.4823])\r\n",
        "std = np.array([0.191473164, 0.191473164, 0.191473164])\r\n",
        "\r\n",
        "\r\n",
        "# mean = np.array([0.4823])\r\n",
        "# std = np.array([19147.3164])\r\n",
        "# mean = np.array([0.4823])\r\n",
        "# std = np.array([0.5])\r\n",
        "# mean = np.array([0.5057, 0.5057, 0.5057])\r\n",
        "# std = np.array([0.1902, 0.1902, 0.1902])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD6dPyTlt_lR"
      },
      "source": [
        "from PIL import Image\r\n",
        "\r\n",
        "\r\n",
        "class RANZCRDataset(Dataset):\r\n",
        "\r\n",
        "\r\n",
        "    def __init__(self, csv_file='/content/trainset/train.csv', root_dir='/content/trainset/data/1', transform=transform, images_name=None):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            csv_file (string): Path to the csv file with annotations.\r\n",
        "            root_dir (string): Directory with all the images.\r\n",
        "            transform (callable, optional): Optional transform to be applied\r\n",
        "                on a sample.\r\n",
        "        \"\"\"\r\n",
        "        self.Images_name = images_name\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.transform = transform\r\n",
        "        \r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.Images_name)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if torch.is_tensor(idx):\r\n",
        "            idx = idx.tolist()\r\n",
        "\r\n",
        "        img_name = os.path.join(self.root_dir,\r\n",
        "                                self.Images_name.iloc[idx, 0])\r\n",
        "        image = Image.open(img_name + '.jpg').convert('RGB')\r\n",
        "        labels = self.Images_name.iloc[idx, 1:-1].values\r\n",
        "        labels = labels.astype(np.int)\r\n",
        "        labels = torch.from_numpy(labels)\r\n",
        "        sample = {'image': image, 'label': labels }\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "\r\n",
        "          sample['image'] = self.transform(sample['image'])\r\n",
        "\r\n",
        "\r\n",
        "        return sample"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgSZrpo8RAxk"
      },
      "source": [
        "import torch\r\n",
        "from torchvision import datasets, transforms\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "def load_data(csv_file='/content/trainset/train.csv', data_dir='/content/trainset/data/1'):\r\n",
        "\r\n",
        "  transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "                                  transforms.Resize((1024, 1024)),\r\n",
        "                                  transforms.CenterCrop(904),\r\n",
        "                                  transforms.Normalize(mean, std)])\r\n",
        "\r\n",
        "\r\n",
        "  trainset = RANZCRDataset(csv_file=csv_file,\r\n",
        "                                      root_dir=data_dir, transform=transform, images_name=images_name)\r\n",
        "\r\n",
        "\r\n",
        "  validation = RANZCRDataset(csv_file=csv_file,\r\n",
        "                                    root_dir=data_dir, transform=transform, images_name=validation_names)\r\n",
        "  \r\n",
        "\r\n",
        "  \r\n",
        "  return trainset, validation\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Tocrklk9gY"
      },
      "source": [
        "# train_data_loader = torch.utils.data.DataLoader(trainset,\r\n",
        "#                                           batch_size=8,\r\n",
        "#                                           shuffle=True,\r\n",
        "#                                           num_workers=0)\r\n",
        "\r\n",
        "\r\n",
        "# validation_data_loader = torch.utils.data.DataLoader(validation,\r\n",
        "#                                           batch_size=8,\r\n",
        "#                                           shuffle=True,\r\n",
        "#                                           num_workers=0)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8muYGHBGwZen"
      },
      "source": [
        "# def imshow(img):\r\n",
        "#     npimg = img.numpy()\r\n",
        "#     npimg = ((npimg * std[0]) + mean[0]) # unnormalize\r\n",
        "#     plt.imshow((np.transpose(npimg, (1, 2, 0)) * 255).astype(np.uint8))\r\n",
        "#     plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# # get some random training images\r\n",
        "# dataiter = iter(train_data_loader)\r\n",
        "# sample = dataiter.next()\r\n",
        "# print(sample['image'].shape)\r\n",
        "# imshow(torchvision.utils.make_grid(sample['image']))\r\n",
        "# print(sample['label'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dpyq8uYr8-7"
      },
      "source": [
        "model = torchvision.models.resnet152(pretrained=False, progress=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oFre0HvsMRj"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpItSJloHImE"
      },
      "source": [
        "for param in model.parameters():\r\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLymbGLgMpu_"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F \r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "  \r\n",
        "  def __init__(self, l1=512, l2=256):\r\n",
        "    super(Net, self).__init__()\r\n",
        "    self.model = model\r\n",
        "    self.conv1 = nn.Conv2d(3, 3, 5)\r\n",
        "    self.conv2 = nn.Conv2d(3, 3, 1)\r\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\r\n",
        "    self.sigmoid = nn.Sigmoid()\r\n",
        "    self.fc1 = nn.Linear(1000, l1)\r\n",
        "    self.fc2 = nn.Linear(l1, l2)\r\n",
        "    self.fc_final = nn.Linear(l2, 11)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    x = self.pool2(F.relu(self.conv1(x)))\r\n",
        "    x = self.pool2(F.relu(self.conv2(x)))\r\n",
        "    x = self.model(x)\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    x = F.relu(self.fc2(x))\r\n",
        "    x = self.sigmoid(self.fc_final(x))\r\n",
        "    return x\r\n",
        "\r\n",
        "# Network = Net()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_7y4DPkHgjH"
      },
      "source": [
        "# def count_parameters(model):\r\n",
        "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "# print(count_parameters(model))\r\n",
        "# print(count_parameters(Network))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Wb3uf0gF3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c896167b-690b-4cb9-aacc-28c766f96e06"
      },
      "source": [
        "\r\n",
        "# Network.load_state_dict(torch.load('/content/drive/MyDrive/model.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DrXdrMNoE6s"
      },
      "source": [
        "# ####################################\r\n",
        "# !pip install ray\r\n",
        "# !pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2jjjLlPnfOl"
      },
      "source": [
        "\r\n",
        "from functools import partial\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import random_split\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from ray import tune\r\n",
        "from ray.tune import CLIReporter\r\n",
        "from ray.tune.schedulers import ASHAScheduler\r\n",
        "import tensorboardX"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN88p-B3m3PU"
      },
      "source": [
        "def train_ranzcr(config, checkpoint_dir=None, data_dir=None):\r\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\r\n",
        "\r\n",
        "    device = \"cpu\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = \"cuda:0\"\r\n",
        "        if torch.cuda.device_count() > 1:\r\n",
        "            net = nn.DataParallel(net)\r\n",
        "    net.to(device)\r\n",
        "\r\n",
        "    criterion = nn.BCELoss()\r\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=config[\"wd\"])\r\n",
        "\r\n",
        "    if checkpoint_dir:\r\n",
        "        model_state, optimizer_state = torch.load(\r\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\r\n",
        "        net.load_state_dict(model_state)\r\n",
        "        optimizer.load_state_dict(optimizer_state)\r\n",
        "\r\n",
        "    trainset, testset = load_data(data_dir)\r\n",
        "\r\n",
        "    test_abs = int(len(trainset) * 0.8)\r\n",
        "    train_subset, val_subset = random_split(\r\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\r\n",
        "\r\n",
        "    trainloader = torch.utils.data.DataLoader(\r\n",
        "        train_subset,\r\n",
        "        batch_size=int(config[\"batch_size\"]),\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=8)\r\n",
        "    valloader = torch.utils.data.DataLoader(\r\n",
        "        val_subset,\r\n",
        "        batch_size=int(config[\"batch_size\"]),\r\n",
        "        shuffle=True,\r\n",
        "        num_workers=8)\r\n",
        "\r\n",
        "    for epoch in range(10):  # loop over the dataset multiple times\r\n",
        "        running_loss = 0.0\r\n",
        "        epoch_steps = 0\r\n",
        "        for i, data in enumerate(trainloader, 0):\r\n",
        "            # get the inputs; data is a list of [inputs, labels]\r\n",
        "            inputs, labels = data['image'].float(), data['label'].float()\r\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "            # zero the parameter gradients\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            # forward + backward + optimize\r\n",
        "            outputs = net(inputs)\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            # print statistics\r\n",
        "            running_loss += loss.item()\r\n",
        "            epoch_steps += 1\r\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\r\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\r\n",
        "                                                running_loss / epoch_steps))\r\n",
        "                running_loss = 0.0\r\n",
        "\r\n",
        "        # Validation loss\r\n",
        "        val_loss = 0.0\r\n",
        "        val_steps = 0\r\n",
        "        total = 0\r\n",
        "        correct = 0\r\n",
        "        for i, data in enumerate(valloader, 0):\r\n",
        "            with torch.no_grad():\r\n",
        "                inputs, labels = data['image'].float(), data['label'].float()\r\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "                outputs = net(inputs)\r\n",
        "                _, predicted = torch.max(outputs.data, 1)\r\n",
        "                print(labels)\r\n",
        "                total += labels.size(0)\r\n",
        "                print(\"HIIIIIIIIIIIIIIIIIIIIIII predicted\", predicted.shape)\r\n",
        "                print(\"HIIIIIIIIIIIIIIIIIIIIIII label\", labels.shape)\r\n",
        "                correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "                loss = criterion(outputs, labels)\r\n",
        "                val_loss += loss.cpu().numpy()\r\n",
        "                val_steps += 1\r\n",
        "\r\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\r\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\r\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\r\n",
        "\r\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\r\n",
        "    print(\"Finished Training\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCprU3xDng_X"
      },
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\r\n",
        "    trainset, testset = load_data()\r\n",
        "\r\n",
        "    testloader = torch.utils.data.DataLoader(\r\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2)\r\n",
        "\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in testloader:\r\n",
        "            images, labels = data['image'].float(), data['label'].float()\r\n",
        "            images, labels = images.to(device), labels.to(device)\r\n",
        "            outputs = net(images)\r\n",
        "            _, predicted = torch.max(outputs.data, 1)\r\n",
        "            total += labels.size(0)\r\n",
        "            correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "    return correct / total"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4x9x0Gvnl1M",
        "outputId": "7fa3d873-f4b2-42a0-dfb3-ffbccaad4ff2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\r\n",
        "    data_dir = os.path.abspath(\"/content/trainset/data\")\r\n",
        "    load_data(data_dir)\r\n",
        "    config = {\r\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(5, 9)),\r\n",
        "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(4, 9)),\r\n",
        "        \"lr\": tune.loguniform(1e-5, 1e-1),\r\n",
        "        \"wd\": tune.loguniform(1e-6, 1e-2),\r\n",
        "        \"batch_size\": tune.choice([4, 8, 16])\r\n",
        "    }\r\n",
        "    scheduler = ASHAScheduler(\r\n",
        "        metric=\"loss\",\r\n",
        "        mode=\"min\",\r\n",
        "        max_t=max_num_epochs,\r\n",
        "        grace_period=1,\r\n",
        "        reduction_factor=2)\r\n",
        "    reporter = CLIReporter(\r\n",
        "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\r\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\r\n",
        "    result = tune.run(\r\n",
        "        partial(train_ranzcr, data_dir=data_dir),\r\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\r\n",
        "        config=config,\r\n",
        "        num_samples=num_samples,\r\n",
        "        scheduler=scheduler,\r\n",
        "        progress_reporter=reporter)\r\n",
        "\r\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\r\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\r\n",
        "    print(\"Best trial final validation loss: {}\".format(\r\n",
        "        best_trial.last_result[\"loss\"]))\r\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\r\n",
        "        best_trial.last_result[\"accuracy\"]))\r\n",
        "\r\n",
        "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\r\n",
        "    device = \"cpu\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        device = \"cuda:0\"\r\n",
        "        if gpus_per_trial > 1:\r\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\r\n",
        "    best_trained_model.to(device)\r\n",
        "\r\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\r\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\r\n",
        "        best_checkpoint_dir, \"checkpoint\"))\r\n",
        "    best_trained_model.load_state_dict(model_state)\r\n",
        "\r\n",
        "    test_acc = test_accuracy(best_trained_model, device)\r\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # You can change the number of GPUs per trial here:\r\n",
        "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-31 13:56:56,540\tWARNING experiment.py:285 -- No name detected on trainable. Using DEFAULT.\n",
            "2021-01-31 13:56:56,541\tINFO registry.py:65 -- Detected unknown callable for trainable. Converting to class.\n",
            "2021-01-31 13:57:13,329\tWARNING worker.py:1034 -- Warning: The actor ImplicitFunc has size 241788462 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n",
            "2021-01-31 13:57:14,614\tWARNING util.py:142 -- The `start_trial` operation took 12.943 s, which may be a performance bottleneck.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 3.3/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2/2 CPUs, 0/1 GPUs, 0.0/7.52 GiB heap, 0.0/2.59 GiB objects (0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/DEFAULT_2021-01-31_13-56-57\n",
            "Number of trials: 1/10 (1 RUNNING)\n",
            "+---------------------+----------+-------+--------------+------+------+-------------+------------+\n",
            "| Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |         wd |\n",
            "|---------------------+----------+-------+--------------+------+------+-------------+------------|\n",
            "| DEFAULT_2fab7_00000 | RUNNING  |       |            8 |   64 |  256 | 2.73852e-05 | 0.00167869 |\n",
            "+---------------------+----------+-------+--------------+------+------+-------------+------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m tensor([[0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m 2021-01-31 14:00:36,105\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 248, in run\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"<ipython-input-22-01a5d79cb679>\", line 76, in train_ranzcr\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 27, in wrapped\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     return f(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m RuntimeError: The size of tensor a (16) must match the size of tensor b (11) at non-singleton dimension 1\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m Exception in thread Thread-2:\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 267, in run\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 248, in run\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"<ipython-input-22-01a5d79cb679>\", line 76, in train_ranzcr\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 27, in wrapped\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m     return f(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m RuntimeError: The size of tensor a (16) must match the size of tensor b (11) at non-singleton dimension 1\n",
            "\u001b[2m\u001b[36m(pid=1561)\u001b[0m \n",
            "2021-01-31 14:00:41,312\tERROR worker.py:980 -- Possible unhandled error from worker: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1561, ip=172.28.0.2)\n",
            "  File \"python/ray/_raylet.pyx\", line 463, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 415, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/trainable.py\", line 183, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 366, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
            "    .format(err_tb_str)))\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1561, ip=172.28.0.2)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 248, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ray/tune/function_runner.py\", line 575, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-22-01a5d79cb679>\", line 76, in train_ranzcr\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 27, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "RuntimeError: The size of tensor a (16) must match the size of tensor b (11) at non-singleton dimension 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F8h5at-Ynoc"
      },
      "source": [
        "#############################################################################\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "\r\n",
        "loss_function = nn.BCELoss()\r\n",
        "optimizer = optim.SGD(Network.parameters(), lr = 0.0075, momentum = 0.9, weight_decay = 1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSY9uhoeWodl"
      },
      "source": [
        "def roc_auc_compute_fn(y_preds, y_targets):\r\n",
        "\r\n",
        "    \r\n",
        "    try:\r\n",
        "        from sklearn.metrics import roc_auc_score\r\n",
        "    except ImportError:\r\n",
        "        raise RuntimeError(\"This contrib module requires sklearn to be installed.\")\r\n",
        "\r\n",
        "    y_true = y_targets.detach().numpy()\r\n",
        "    y_pred = y_preds.detach().numpy()\r\n",
        "\r\n",
        "    try:\r\n",
        "      return roc_auc_score(y_true, y_pred, average='micro')\r\n",
        "    except ValueError:\r\n",
        "      return None\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjwmUvBRYqR6",
        "outputId": "fef370bf-fd90-4d34-f9f1-da9ef5918505"
      },
      "source": [
        "for epoch in range(20):\r\n",
        "\r\n",
        "  running_loss = 0.0\r\n",
        "  best_validation_auc_score = 0\r\n",
        "\r\n",
        "  for i, data in enumerate(train_data_loader, 0):\r\n",
        "    \r\n",
        "\r\n",
        "    inputs = data['image'].float()\r\n",
        "    label = data['label'].float()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    outputs = Network(inputs)\r\n",
        "    loss = loss_function(outputs, label)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    auc_score = roc_auc_compute_fn(outputs, label)\r\n",
        "    running_loss += loss.item()\r\n",
        "    if (i % 10 == 0) and (i > 9):\r\n",
        "      print('[epoch: %d, batch: %5d] training loss: %.3f training auc score: %.3f' %( epoch + 1, i, (running_loss/10), auc_score))\r\n",
        "      \r\n",
        "      dataiter = iter(validation_data_loader)\r\n",
        "      sample = dataiter.next()\r\n",
        "      validation_inputs = sample['image'].float()\r\n",
        "      validation_label = sample['label'].float()\r\n",
        "      validation_outputs = Network(validation_inputs)\r\n",
        "      validation_loss = loss_function(validation_outputs, validation_label)\r\n",
        "      validation_auc_score = roc_auc_compute_fn(validation_outputs, validation_label)\r\n",
        "\r\n",
        "      print('[epoch: %d, batch: %5d] <validation 10 random sample> loss: %.3f , auc score: %.3f' %( epoch + 1, i, validation_loss, validation_auc_score))\r\n",
        "\r\n",
        "\r\n",
        "      running_loss = 0.0\r\n",
        "\r\n",
        "  try:\r\n",
        "    if validation_auc_score > best_validation_auc_score:\r\n",
        "      torch.save(Network.state_dict(), '/content/drive/MyDrive/model_second_train.pth')\r\n",
        "      best_validation_auc_score = validation_auc_score\r\n",
        "  except ValueError:\r\n",
        "    pass\r\n",
        "  \r\n",
        "    \r\n",
        "print('Finished Training Network')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch: 1, batch:    10] training loss: 10.695 training auc score: 0.644\n",
            "[epoch: 1, batch:    10] <validation 10 random sample> loss: 7.356 , auc score: 0.613\n",
            "[epoch: 1, batch:    20] training loss: 9.494 training auc score: 0.748\n",
            "[epoch: 1, batch:    20] <validation 10 random sample> loss: 7.212 , auc score: 0.693\n",
            "[epoch: 1, batch:    30] training loss: 9.124 training auc score: 0.687\n",
            "[epoch: 1, batch:    30] <validation 10 random sample> loss: 6.029 , auc score: 0.674\n",
            "[epoch: 1, batch:    40] training loss: 7.188 training auc score: 0.681\n",
            "[epoch: 1, batch:    40] <validation 10 random sample> loss: 8.255 , auc score: 0.694\n",
            "[epoch: 1, batch:    50] training loss: 7.859 training auc score: 0.689\n",
            "[epoch: 1, batch:    50] <validation 10 random sample> loss: 3.890 , auc score: 0.774\n",
            "[epoch: 1, batch:    60] training loss: 7.494 training auc score: 0.733\n",
            "[epoch: 1, batch:    60] <validation 10 random sample> loss: 9.479 , auc score: 0.542\n",
            "[epoch: 1, batch:    70] training loss: 7.870 training auc score: 0.577\n",
            "[epoch: 1, batch:    70] <validation 10 random sample> loss: 11.749 , auc score: 0.722\n",
            "[epoch: 1, batch:    80] training loss: 6.961 training auc score: 0.713\n",
            "[epoch: 1, batch:    80] <validation 10 random sample> loss: 7.171 , auc score: 0.733\n",
            "[epoch: 1, batch:    90] training loss: 8.904 training auc score: 0.689\n",
            "[epoch: 1, batch:    90] <validation 10 random sample> loss: 4.948 , auc score: 0.701\n",
            "[epoch: 1, batch:   100] training loss: 7.610 training auc score: 0.745\n",
            "[epoch: 1, batch:   100] <validation 10 random sample> loss: 8.335 , auc score: 0.755\n",
            "[epoch: 1, batch:   110] training loss: 9.116 training auc score: 0.585\n",
            "[epoch: 1, batch:   110] <validation 10 random sample> loss: 8.409 , auc score: 0.661\n",
            "[epoch: 1, batch:   120] training loss: 7.437 training auc score: 0.736\n",
            "[epoch: 1, batch:   120] <validation 10 random sample> loss: 9.415 , auc score: 0.575\n",
            "[epoch: 1, batch:   130] training loss: 6.492 training auc score: 0.795\n",
            "[epoch: 1, batch:   130] <validation 10 random sample> loss: 6.134 , auc score: 0.624\n",
            "[epoch: 1, batch:   140] training loss: 7.588 training auc score: 0.577\n",
            "[epoch: 1, batch:   140] <validation 10 random sample> loss: 6.055 , auc score: 0.764\n",
            "[epoch: 1, batch:   150] training loss: 7.770 training auc score: 0.621\n",
            "[epoch: 1, batch:   150] <validation 10 random sample> loss: 7.221 , auc score: 0.734\n",
            "[epoch: 1, batch:   160] training loss: 7.772 training auc score: 0.723\n",
            "[epoch: 1, batch:   160] <validation 10 random sample> loss: 6.063 , auc score: 0.671\n",
            "[epoch: 1, batch:   170] training loss: 6.833 training auc score: 0.671\n",
            "[epoch: 1, batch:   170] <validation 10 random sample> loss: 7.211 , auc score: 0.732\n",
            "[epoch: 1, batch:   180] training loss: 8.538 training auc score: 0.706\n",
            "[epoch: 1, batch:   180] <validation 10 random sample> loss: 8.380 , auc score: 0.623\n",
            "[epoch: 1, batch:   190] training loss: 6.847 training auc score: 0.708\n",
            "[epoch: 1, batch:   190] <validation 10 random sample> loss: 6.139 , auc score: 0.671\n",
            "[epoch: 1, batch:   200] training loss: 7.619 training auc score: 0.720\n",
            "[epoch: 1, batch:   200] <validation 10 random sample> loss: 8.314 , auc score: 0.625\n",
            "[epoch: 1, batch:   210] training loss: 8.694 training auc score: 0.700\n",
            "[epoch: 1, batch:   210] <validation 10 random sample> loss: 10.546 , auc score: 0.746\n",
            "[epoch: 1, batch:   220] training loss: 7.728 training auc score: 0.729\n",
            "[epoch: 1, batch:   220] <validation 10 random sample> loss: 9.491 , auc score: 0.584\n",
            "[epoch: 1, batch:   230] training loss: 8.225 training auc score: 0.577\n",
            "[epoch: 1, batch:   230] <validation 10 random sample> loss: 8.343 , auc score: 0.668\n",
            "[epoch: 1, batch:   240] training loss: 8.229 training auc score: 0.747\n",
            "[epoch: 1, batch:   240] <validation 10 random sample> loss: 7.179 , auc score: 0.665\n",
            "[epoch: 1, batch:   250] training loss: 7.533 training auc score: 0.721\n",
            "[epoch: 1, batch:   250] <validation 10 random sample> loss: 9.434 , auc score: 0.621\n",
            "[epoch: 1, batch:   260] training loss: 8.325 training auc score: 0.650\n",
            "[epoch: 1, batch:   260] <validation 10 random sample> loss: 6.020 , auc score: 0.746\n",
            "[epoch: 1, batch:   270] training loss: 9.332 training auc score: 0.587\n",
            "[epoch: 1, batch:   270] <validation 10 random sample> loss: 6.041 , auc score: 0.786\n",
            "[epoch: 1, batch:   280] training loss: 7.872 training auc score: 0.656\n",
            "[epoch: 1, batch:   280] <validation 10 random sample> loss: 19.863 , auc score: 0.433\n",
            "[epoch: 1, batch:   290] training loss: 8.311 training auc score: 0.621\n",
            "[epoch: 1, batch:   290] <validation 10 random sample> loss: 12.860 , auc score: 0.697\n",
            "[epoch: 1, batch:   300] training loss: 7.850 training auc score: 0.757\n",
            "[epoch: 1, batch:   300] <validation 10 random sample> loss: 8.267 , auc score: 0.642\n",
            "[epoch: 1, batch:   310] training loss: 8.733 training auc score: 0.743\n",
            "[epoch: 1, batch:   310] <validation 10 random sample> loss: 8.408 , auc score: 0.682\n",
            "[epoch: 1, batch:   320] training loss: 7.266 training auc score: 0.802\n",
            "[epoch: 1, batch:   320] <validation 10 random sample> loss: 10.410 , auc score: 0.632\n",
            "[epoch: 1, batch:   330] training loss: 8.438 training auc score: 0.780\n",
            "[epoch: 1, batch:   330] <validation 10 random sample> loss: 8.319 , auc score: 0.686\n",
            "[epoch: 1, batch:   340] training loss: 7.958 training auc score: 0.847\n",
            "[epoch: 1, batch:   340] <validation 10 random sample> loss: 8.362 , auc score: 0.589\n",
            "[epoch: 1, batch:   350] training loss: 7.384 training auc score: 0.804\n",
            "[epoch: 1, batch:   350] <validation 10 random sample> loss: 4.967 , auc score: 0.807\n",
            "[epoch: 1, batch:   360] training loss: 8.344 training auc score: 0.700\n",
            "[epoch: 1, batch:   360] <validation 10 random sample> loss: 8.457 , auc score: 0.599\n",
            "[epoch: 1, batch:   370] training loss: 8.597 training auc score: 0.602\n",
            "[epoch: 1, batch:   370] <validation 10 random sample> loss: 6.092 , auc score: 0.776\n",
            "[epoch: 1, batch:   380] training loss: 7.507 training auc score: 0.720\n",
            "[epoch: 1, batch:   380] <validation 10 random sample> loss: 9.559 , auc score: 0.570\n",
            "[epoch: 1, batch:   390] training loss: 8.419 training auc score: 0.632\n",
            "[epoch: 1, batch:   390] <validation 10 random sample> loss: 10.576 , auc score: 0.573\n",
            "[epoch: 1, batch:   400] training loss: 8.285 training auc score: 0.650\n",
            "[epoch: 1, batch:   400] <validation 10 random sample> loss: 7.211 , auc score: 0.716\n",
            "[epoch: 1, batch:   410] training loss: 6.749 training auc score: 0.650\n",
            "[epoch: 1, batch:   410] <validation 10 random sample> loss: 9.707 , auc score: 0.491\n",
            "[epoch: 1, batch:   420] training loss: 8.737 training auc score: 0.787\n",
            "[epoch: 1, batch:   420] <validation 10 random sample> loss: 6.101 , auc score: 0.727\n",
            "[epoch: 1, batch:   430] training loss: 6.735 training auc score: 0.834\n",
            "[epoch: 1, batch:   430] <validation 10 random sample> loss: 6.074 , auc score: 0.729\n",
            "[epoch: 1, batch:   440] training loss: 9.433 training auc score: 0.687\n",
            "[epoch: 1, batch:   440] <validation 10 random sample> loss: 7.121 , auc score: 0.725\n",
            "[epoch: 1, batch:   450] training loss: 8.869 training auc score: 0.747\n",
            "[epoch: 1, batch:   450] <validation 10 random sample> loss: 8.245 , auc score: 0.767\n",
            "[epoch: 1, batch:   460] training loss: 7.854 training auc score: 0.598\n",
            "[epoch: 1, batch:   460] <validation 10 random sample> loss: 8.262 , auc score: 0.735\n",
            "[epoch: 1, batch:   470] training loss: 7.157 training auc score: 0.688\n",
            "[epoch: 1, batch:   470] <validation 10 random sample> loss: 10.822 , auc score: 0.634\n",
            "[epoch: 1, batch:   480] training loss: 7.447 training auc score: 0.626\n",
            "[epoch: 1, batch:   480] <validation 10 random sample> loss: 6.066 , auc score: 0.712\n",
            "[epoch: 1, batch:   490] training loss: 8.773 training auc score: 0.807\n",
            "[epoch: 1, batch:   490] <validation 10 random sample> loss: 6.067 , auc score: 0.670\n",
            "[epoch: 1, batch:   500] training loss: 7.321 training auc score: 0.754\n",
            "[epoch: 1, batch:   500] <validation 10 random sample> loss: 7.179 , auc score: 0.680\n",
            "[epoch: 1, batch:   510] training loss: 8.529 training auc score: 0.785\n",
            "[epoch: 1, batch:   510] <validation 10 random sample> loss: 7.155 , auc score: 0.793\n",
            "[epoch: 1, batch:   520] training loss: 6.778 training auc score: 0.579\n",
            "[epoch: 1, batch:   520] <validation 10 random sample> loss: 7.213 , auc score: 0.734\n",
            "[epoch: 1, batch:   530] training loss: 8.331 training auc score: 0.718\n",
            "[epoch: 1, batch:   530] <validation 10 random sample> loss: 5.977 , auc score: 0.784\n",
            "[epoch: 1, batch:   540] training loss: 6.492 training auc score: 0.747\n",
            "[epoch: 1, batch:   540] <validation 10 random sample> loss: 6.102 , auc score: 0.722\n",
            "[epoch: 1, batch:   550] training loss: 7.606 training auc score: 0.726\n",
            "[epoch: 1, batch:   550] <validation 10 random sample> loss: 6.099 , auc score: 0.759\n",
            "[epoch: 1, batch:   560] training loss: 7.756 training auc score: 0.776\n",
            "[epoch: 1, batch:   560] <validation 10 random sample> loss: 3.719 , auc score: 0.865\n",
            "[epoch: 1, batch:   570] training loss: 7.046 training auc score: 0.734\n",
            "[epoch: 1, batch:   570] <validation 10 random sample> loss: 7.131 , auc score: 0.698\n",
            "[epoch: 1, batch:   580] training loss: 7.356 training auc score: 0.634\n",
            "[epoch: 1, batch:   580] <validation 10 random sample> loss: 8.220 , auc score: 0.702\n",
            "[epoch: 1, batch:   590] training loss: 6.512 training auc score: 0.795\n",
            "[epoch: 1, batch:   590] <validation 10 random sample> loss: 3.807 , auc score: 0.752\n",
            "[epoch: 1, batch:   600] training loss: 9.115 training auc score: 0.758\n",
            "[epoch: 1, batch:   600] <validation 10 random sample> loss: 7.162 , auc score: 0.671\n",
            "[epoch: 1, batch:   610] training loss: 7.945 training auc score: 0.782\n",
            "[epoch: 1, batch:   610] <validation 10 random sample> loss: 8.336 , auc score: 0.614\n",
            "[epoch: 1, batch:   620] training loss: 6.969 training auc score: 0.681\n",
            "[epoch: 1, batch:   620] <validation 10 random sample> loss: 8.417 , auc score: 0.609\n",
            "[epoch: 1, batch:   630] training loss: 7.075 training auc score: 0.746\n",
            "[epoch: 1, batch:   630] <validation 10 random sample> loss: 6.036 , auc score: 0.699\n",
            "[epoch: 1, batch:   640] training loss: 7.855 training auc score: 0.805\n",
            "[epoch: 1, batch:   640] <validation 10 random sample> loss: 15.060 , auc score: 0.635\n",
            "[epoch: 1, batch:   650] training loss: 7.892 training auc score: 0.577\n",
            "[epoch: 1, batch:   650] <validation 10 random sample> loss: 4.887 , auc score: 0.814\n",
            "[epoch: 1, batch:   660] training loss: 7.912 training auc score: 0.716\n",
            "[epoch: 1, batch:   660] <validation 10 random sample> loss: 6.041 , auc score: 0.764\n",
            "[epoch: 1, batch:   670] training loss: 6.641 training auc score: 0.810\n",
            "[epoch: 1, batch:   670] <validation 10 random sample> loss: 11.599 , auc score: 0.738\n",
            "[epoch: 1, batch:   680] training loss: 6.620 training auc score: 0.725\n",
            "[epoch: 1, batch:   680] <validation 10 random sample> loss: 6.027 , auc score: 0.714\n",
            "[epoch: 1, batch:   690] training loss: 8.068 training auc score: 0.675\n",
            "[epoch: 1, batch:   690] <validation 10 random sample> loss: 7.221 , auc score: 0.707\n",
            "[epoch: 1, batch:   700] training loss: 6.276 training auc score: 0.647\n",
            "[epoch: 1, batch:   700] <validation 10 random sample> loss: 12.818 , auc score: 0.616\n",
            "[epoch: 1, batch:   710] training loss: 9.469 training auc score: 0.727\n",
            "[epoch: 1, batch:   710] <validation 10 random sample> loss: 8.435 , auc score: 0.623\n",
            "[epoch: 1, batch:   720] training loss: 8.663 training auc score: 0.800\n",
            "[epoch: 1, batch:   720] <validation 10 random sample> loss: 6.101 , auc score: 0.715\n",
            "[epoch: 1, batch:   730] training loss: 7.581 training auc score: 0.703\n",
            "[epoch: 1, batch:   730] <validation 10 random sample> loss: 13.575 , auc score: 0.667\n",
            "[epoch: 1, batch:   740] training loss: 8.066 training auc score: 0.741\n",
            "[epoch: 1, batch:   740] <validation 10 random sample> loss: 8.315 , auc score: 0.738\n",
            "[epoch: 1, batch:   750] training loss: 8.220 training auc score: 0.670\n",
            "[epoch: 1, batch:   750] <validation 10 random sample> loss: 7.205 , auc score: 0.711\n",
            "[epoch: 1, batch:   760] training loss: 7.589 training auc score: 0.746\n",
            "[epoch: 1, batch:   760] <validation 10 random sample> loss: 8.289 , auc score: 0.695\n",
            "[epoch: 1, batch:   770] training loss: 6.164 training auc score: 0.758\n",
            "[epoch: 1, batch:   770] <validation 10 random sample> loss: 7.111 , auc score: 0.765\n",
            "[epoch: 1, batch:   780] training loss: 7.980 training auc score: 0.735\n",
            "[epoch: 1, batch:   780] <validation 10 random sample> loss: 7.135 , auc score: 0.736\n",
            "[epoch: 1, batch:   790] training loss: 8.878 training auc score: 0.763\n",
            "[epoch: 1, batch:   790] <validation 10 random sample> loss: 12.708 , auc score: 0.640\n",
            "[epoch: 1, batch:   800] training loss: 6.930 training auc score: 0.713\n",
            "[epoch: 1, batch:   800] <validation 10 random sample> loss: 7.170 , auc score: 0.732\n",
            "[epoch: 1, batch:   810] training loss: 7.859 training auc score: 0.700\n",
            "[epoch: 1, batch:   810] <validation 10 random sample> loss: 8.336 , auc score: 0.721\n",
            "[epoch: 1, batch:   820] training loss: 7.518 training auc score: 0.697\n",
            "[epoch: 1, batch:   820] <validation 10 random sample> loss: 8.317 , auc score: 0.732\n",
            "[epoch: 1, batch:   830] training loss: 6.288 training auc score: 0.751\n",
            "[epoch: 1, batch:   830] <validation 10 random sample> loss: 8.407 , auc score: 0.609\n",
            "[epoch: 1, batch:   840] training loss: 7.749 training auc score: 0.664\n",
            "[epoch: 1, batch:   840] <validation 10 random sample> loss: 7.213 , auc score: 0.733\n",
            "[epoch: 1, batch:   850] training loss: 7.538 training auc score: 0.758\n",
            "[epoch: 1, batch:   850] <validation 10 random sample> loss: 8.488 , auc score: 0.512\n",
            "[epoch: 1, batch:   860] training loss: 8.621 training auc score: 0.648\n",
            "[epoch: 1, batch:   860] <validation 10 random sample> loss: 6.077 , auc score: 0.787\n",
            "[epoch: 2, batch:    10] training loss: 8.139 training auc score: 0.739\n",
            "[epoch: 2, batch:    10] <validation 10 random sample> loss: 10.625 , auc score: 0.561\n",
            "[epoch: 2, batch:    20] training loss: 6.711 training auc score: 0.706\n",
            "[epoch: 2, batch:    20] <validation 10 random sample> loss: 8.323 , auc score: 0.555\n",
            "[epoch: 2, batch:    30] training loss: 8.121 training auc score: 0.673\n",
            "[epoch: 2, batch:    30] <validation 10 random sample> loss: 6.073 , auc score: 0.758\n",
            "[epoch: 2, batch:    40] training loss: 6.084 training auc score: 0.628\n",
            "[epoch: 2, batch:    40] <validation 10 random sample> loss: 9.520 , auc score: 0.611\n",
            "[epoch: 2, batch:    50] training loss: 8.012 training auc score: 0.705\n",
            "[epoch: 2, batch:    50] <validation 10 random sample> loss: 7.234 , auc score: 0.650\n",
            "[epoch: 2, batch:    60] training loss: 7.309 training auc score: 0.617\n",
            "[epoch: 2, batch:    60] <validation 10 random sample> loss: 12.938 , auc score: 0.660\n",
            "[epoch: 2, batch:    70] training loss: 7.313 training auc score: 0.709\n",
            "[epoch: 2, batch:    70] <validation 10 random sample> loss: 7.196 , auc score: 0.702\n",
            "[epoch: 2, batch:    80] training loss: 6.761 training auc score: 0.695\n",
            "[epoch: 2, batch:    80] <validation 10 random sample> loss: 6.204 , auc score: 0.691\n",
            "[epoch: 2, batch:    90] training loss: 7.282 training auc score: 0.780\n",
            "[epoch: 2, batch:    90] <validation 10 random sample> loss: 8.319 , auc score: 0.709\n",
            "[epoch: 2, batch:   100] training loss: 8.326 training auc score: 0.687\n",
            "[epoch: 2, batch:   100] <validation 10 random sample> loss: 9.942 , auc score: 0.687\n",
            "[epoch: 2, batch:   110] training loss: 7.549 training auc score: 0.688\n",
            "[epoch: 2, batch:   110] <validation 10 random sample> loss: 7.212 , auc score: 0.695\n",
            "[epoch: 2, batch:   120] training loss: 8.526 training auc score: 0.741\n",
            "[epoch: 2, batch:   120] <validation 10 random sample> loss: 6.064 , auc score: 0.717\n",
            "[epoch: 2, batch:   130] training loss: 8.298 training auc score: 0.723\n",
            "[epoch: 2, batch:   130] <validation 10 random sample> loss: 8.446 , auc score: 0.593\n",
            "[epoch: 2, batch:   140] training loss: 6.622 training auc score: 0.773\n",
            "[epoch: 2, batch:   140] <validation 10 random sample> loss: 8.350 , auc score: 0.643\n",
            "[epoch: 2, batch:   150] training loss: 7.537 training auc score: 0.745\n",
            "[epoch: 2, batch:   150] <validation 10 random sample> loss: 6.033 , auc score: 0.670\n",
            "[epoch: 2, batch:   160] training loss: 9.182 training auc score: 0.789\n",
            "[epoch: 2, batch:   160] <validation 10 random sample> loss: 8.287 , auc score: 0.688\n",
            "[epoch: 2, batch:   170] training loss: 6.583 training auc score: 0.741\n",
            "[epoch: 2, batch:   170] <validation 10 random sample> loss: 6.034 , auc score: 0.683\n",
            "[epoch: 2, batch:   180] training loss: 7.890 training auc score: 0.725\n",
            "[epoch: 2, batch:   180] <validation 10 random sample> loss: 6.098 , auc score: 0.719\n",
            "[epoch: 2, batch:   190] training loss: 7.404 training auc score: 0.546\n",
            "[epoch: 2, batch:   190] <validation 10 random sample> loss: 6.140 , auc score: 0.714\n",
            "[epoch: 2, batch:   200] training loss: 9.383 training auc score: 0.674\n",
            "[epoch: 2, batch:   200] <validation 10 random sample> loss: 7.190 , auc score: 0.703\n",
            "[epoch: 2, batch:   210] training loss: 8.081 training auc score: 0.774\n",
            "[epoch: 2, batch:   210] <validation 10 random sample> loss: 13.926 , auc score: 0.687\n",
            "[epoch: 2, batch:   220] training loss: 7.576 training auc score: 0.730\n",
            "[epoch: 2, batch:   220] <validation 10 random sample> loss: 6.080 , auc score: 0.740\n",
            "[epoch: 2, batch:   230] training loss: 8.410 training auc score: 0.672\n",
            "[epoch: 2, batch:   230] <validation 10 random sample> loss: 6.043 , auc score: 0.731\n",
            "[epoch: 2, batch:   240] training loss: 8.724 training auc score: 0.627\n",
            "[epoch: 2, batch:   240] <validation 10 random sample> loss: 6.058 , auc score: 0.792\n",
            "[epoch: 2, batch:   250] training loss: 6.736 training auc score: 0.710\n",
            "[epoch: 2, batch:   250] <validation 10 random sample> loss: 7.203 , auc score: 0.790\n",
            "[epoch: 2, batch:   260] training loss: 6.505 training auc score: 0.781\n",
            "[epoch: 2, batch:   260] <validation 10 random sample> loss: 9.453 , auc score: 0.584\n",
            "[epoch: 2, batch:   270] training loss: 6.953 training auc score: 0.713\n",
            "[epoch: 2, batch:   270] <validation 10 random sample> loss: 4.862 , auc score: 0.820\n",
            "[epoch: 2, batch:   280] training loss: 6.490 training auc score: 0.682\n",
            "[epoch: 2, batch:   280] <validation 10 random sample> loss: 4.894 , auc score: 0.762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "LQkE8mE4ssFm",
        "outputId": "32ca152d-475c-464f-cd2e-56d8ff46895e"
      },
      "source": [
        "# Quick evaluation \r\n",
        "\r\n",
        "# get some random training images\r\n",
        "dataiter = iter(train_data_loader)\r\n",
        "sample = dataiter.next()\r\n",
        "inputs = sample['image'].float()\r\n",
        "label = sample['label'].float()\r\n",
        "print(inputs.shape)\r\n",
        "batch_predicted_values = Network(inputs)\r\n",
        "imshow(torchvision.utils.make_grid(sample['image']))\r\n",
        "print(sample['label'])\r\n",
        "print(batch_predicted_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 904, 904])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1],\n",
            "        [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor([[0.0714, 0.0890, 0.5512, 0.1069, 0.1224, 0.1886, 0.5511, 0.0882, 0.0762,\n",
            "         0.8075, 0.1462],\n",
            "        [0.1319, 0.0933, 0.2090, 0.0392, 0.0445, 0.1242, 0.4983, 0.1084, 0.1159,\n",
            "         0.6736, 0.1975],\n",
            "        [0.0784, 0.0943, 0.5275, 0.0987, 0.1119, 0.1845, 0.5557, 0.0974, 0.0803,\n",
            "         0.8101, 0.1670],\n",
            "        [0.1192, 0.0823, 0.1879, 0.0377, 0.0430, 0.1216, 0.4869, 0.1080, 0.1237,\n",
            "         0.6789, 0.1908]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnhhfYNZJbhc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}